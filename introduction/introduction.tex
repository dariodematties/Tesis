\chapter{Introducción}

\section{Motivación y Objetivos}

Evidencia comportamental muestra que humanos y otros animales pueden clasificar fonemas como así también otras unidades lingüísticas de manera categórica. También pueden generalizar en presencia de la variabilidad impuesta por diferentes hablantes con diferentes tonos de voz y prosodia, aún en ambientes ruidosos y con reverberación~\cite{kuhl_1975, kuhl_1983, kluender_1998, pons_2006, hienz_1996, dent_1997, lotto_1997}.

%Behavioral evidence shows that humans and other animals can classify phonemes as well as other linguistic units categorically. They can also generalize in the presence of the variability imposed by different speakers with different pitches and prosody, even in noisy and reverberant environments~\cite{kuhl_1975, kuhl_1983, kluender_1998, pons_2006, hienz_1996, dent_1997, lotto_1997}.

Evidencia neurofisiológica sostiene tal comportamiento revelando la existencia de respuestas espectro-temporales en \gls{a1} en hurones. Las activaciones corticales medidas en tales animales sostienen la discriminación fonética~\cite{mesgarani_2008}, aún cuando el estímulo se distorsiona con ruido aditivo y reverberación \cite{mesgarani_2014A}.

%Neurophysiological evidence support such behavior revealing the existence of spectro-temporal tuning in naive ferrets' \gls{a1}. Cortical activations measured in such animals support phonetic discrimination~\cite{mesgarani_2008}, even when stimuli is distorted by additive noise and reverberation \cite{mesgarani_2014A}.

%Which are the neuroanatomical and neurophysiological features in cortical tissue that support such evidence? Although many computational theories have been developed, they only explain relevant aspects of phonetic acquisition~\cite{rasanen_2012}. Others are mainly proposed to improve audio classification accuracy using \glspl{cdbn} \cite{Lee:2009:UFL:2984093.2984217} and \glspl{dmn}~\cite{silos_2016}. Such approaches neglect important biological properties recently found in cortical tissue.

%Instead, we implemented a computational theory which incorporates specific properties present in the mammalian cortex. We foresee such properties as relevant for the acquisition of the sequential phonotactic rules of a language. 

Para entender como se adquieren las distintas categorías fonéticas como así también las unidades fonotácticas similares a palabras se han desarrollado diversas teorías computacionales \cite{rasanen_2012}. En el contexto de tales teorías, la idea principal ha sido la de explicar aspectos relevantes de la adquisición fonética apelando al uso de la ingeniería y la experiencia humana de expertos y profesionales en la materia. De todas formas, dada la gran cantidad de variables interrelacionadas en los procesos de categorización fonética, algunos fenómenos como la \emph{ausencia de invarianza} en la percepción del habla \cite{appelbaum_1996} parecen posicionarse como uno de esos problemas científicos de resolución imposible para el razonamiento humano espontáneo. En este sentido, las arquitecturas de aprendizaje profundo--dentro del aprendizaje de representaciones--han mostrado niveles sin precedente en la asistencia a técnicas convencionales de aprendizaje supervisado de máquinas, las que por décadas se han valido de altos niveles de ingeniería y de dominio experto para obtener diseños efectivos en la extracción de características desde los datos crudos de entrada \cite{lecun_2015}.

%To understand how phonetic categories and word-like units are acquired, several computational theories have been developed \cite{rasanen_2012}. In the context of such theories, the main idea has been to explain relevant aspects of phonetic acquisition by means of human engineered features. Nevertheless, \emph{lack of invariance} phenomenon in speech perception \cite{appelbaum_1996} seems to be one of those scientific problems which cannot be solved by spontaneous human reasoning, given the immense amount of interrelated variables involved in phonetic categorization processes. In that sense, \emph{deep learning} architectures--as a subfield inside of \emph{representation learning}--have shown unprecedented performance in the assistance of conventional machine learning techniques, which for decades  required careful engineering in order to reach an effective feature extraction design \cite{lecun_2015}.


\subsection{Características Diseñadas por Humanos}

Entre las teorías computacionales desarrolladas para entender la adquisición fonética en humanos, algunos modelos pasan por alto el procesamiento inicial de la señal del habla y, en lugar de lidiar con la complejidad y variabilidad de la señal de habla real, utilizan representaciones pre-léxicas discretas e idealizadas de la señal acústica como entrada al nivel léxico \cite{scharenborg_2010}. Dichas representaciones son diseñadas artificialmente por medio de la intervención humana. Aunque en otros trabajos se hacen algunas observaciones a nivel biológico \cite{dominey_2000}, las componentes de entrada no son más que representaciones silábicas extraídas de corpus específicos. 

%Among the computational theories developed to understand human phonetic acquisition, some models bypass the initial speech signal processing and, instead of dealing with the complexity and variability of real speech at the prelexical level, they use an artificial, often hand-crafted,  idealized discrete (prelexical) representation of the acoustic signal as an input to the lexical level \cite{scharenborg_2010}. In other works \cite{dominey_2000}, although some biological observations are made, the input components are syllable representations from specific corpora.

En los trabajos de Boer y Kuhl \cite{boer_2003} y Vallabha, McLelland, Pons, Werker y Amano \cite{vallabha_2007}, los modelos clasifican algunas vocales por medio de mecanismos estadísticos que toman en consideración componentes formantes y \gls{vl}. En Toscano y McMurray \cite{toscano_2010}, se utilizan métodos estadísticos para clasificar características fonéticas consonánticas, por medio de \gls{vot}, \gls{vl}, tono y primera frecuencia de inicio del formante.

%In the works by de Boer and Kuhl \cite{boer_2003} and Vallabha, McLelland, Pons, Werker and Amano \cite{vallabha_2007}, the models classify some vowels through statistical mechanisms which consider formant components and \gls{vl}. In Toscano and McMurray \cite{toscano_2010}, statistical methods are used to classify consonantal phonetic characteristics, by means of \gls{vot}, \gls{vl}, pitch and first formant onset frequency.

En Kouki et al. \cite{kouki_2010}, la utilización de \gls{mfcc} supone un flujo de entrada más biológicamente plausible. En un trabajo posterior, Kouki et al. \cite{kouki_2011}, diseñaron un método para separar representaciones “estables” y “dinámicas” desde patrones del habla.

%In Kouki et al. \cite{kouki_2010}, the use of \gls{mfcc} strategy presupposes a more biologically accurate input stream. In a subsequent work, Kouki et al. \cite{kouki_2011}, designed a method to separate “stable” and “dynamic” speech patterns.

Los métodos estadísticos utilizados en estos trabajos interrelacionan diferentes características extraídas desde las señales acústicas del habla. Dichas características son sopesadas cuidadosamente por medio de ingeniería y alto nivel de experiencia y dominio humano los que evalúan su relevancia a la hora de incluirlos en las computaciones. Algunas características como \gls{vl} y \gls{vot} son altamente dinámicas y abstractas y se toman como características ampliamente disponibles sin ningún procesamiento neuronal previo. 

%The statistical methods used in such works make different features extracted from acoustic speech signals interrelate. Those features are carefully weighted by means of human engineering and domain expertise, which evaluate their relevance in order to include them in the computations. Some features, as \gls{vl} and \gls{vot}, refer to highly abstract dynamic characteristics which are taken as available parameters without any previous natural processing.

\subsection{Características Diseñadas por Máquinas}

La posibilidad de que existan otras características que puedan escapar a la experiencia humana más el hecho de que algunas características ocultas podrían ser partes constitutivas de aquellas características de alta abstracción evaluadas por humanos permitió el advenimiento de los distintos enfoques del aprendizaje profundo. Dichos enfoques han ganado un extraordinario interés como medio para la construcción automática y jerárquica de de representaciones extraídas desde datos tanto etiquetados como no etiquetados.  

%The possibility of the existence of other features which can escape from human expertise and the fact that some hidden features could be a constituent part of those abstract features evaluated by humans allowed the advent of deep learning approaches which have fairly gained outstanding interest as a way of building hierarchical representations from unlabeled and labeled data.

En referencia al aprendizaje supervisado en múltiples capas, tales arquitecturas pueden ser entrenadas a través de descenso de gradiente estocástico, y las mismas funcionan sorprendentemente bien. Esto fue descubierto de manera independiente por diferentes grupos durante las décadas de 1970 y 1980 \cite{noauthor_9_nodate,noauthor_parker_nodate,lecun_procedure_1985,rumelhart_learning_1986}.  

%Referring to multilayer supervised learning, the fact that such architectures can be trained by simple stochastic gradient descent, and that they work remarkably well, was discovered independently by different groups during the 1970s and 1980s \cite{noauthor_9_nodate,noauthor_parker_nodate,lecun_procedure_1985,rumelhart_learning_1986}.

Sin embargo se tuvo que esperar hasta el año 2006 para que dichas arquitecturas tuvieran su primer impacto de aceptación \cite{hinton_what_2005,hinton_fast_2006,bengio_greedy_2006,ranzato_efficient_2006} cuando un grupo de investigadores introdujo procedimientos de aprendizaje profundo no-supervisados en los que inicialmente se pre-entrenaba una red para finalmente ajustar la misma por medio de algoritmos backpropagation \cite{bengio_greedy_2006,ranzato_efficient_2006,hinton_reducing_2006}. Tales procedimientos rompieron marcas en bancos de prueba estandardizados como parte constitutiva en un sistema completo para reconocimiento de habla para clasificación en vocabularios pequeños \cite{mohamed_acoustic_2012} y grandes \cite{dahl_context-dependent_2012}.

%However, a first widespread acceptance hit of these architectures had to wait until 2006 \cite{hinton_what_2005,hinton_fast_2006,bengio_greedy_2006,ranzato_efficient_2006} when a group of researchers introduced deep unsupervised learning procedures which initially pre-train the network for finally fine-tune it by means of standard backpropagation \cite{bengio_greedy_2006,ranzato_efficient_2006,hinton_reducing_2006}. It returned record-breaking results--as a constituent part of a complete system--on a standard speech recognition benchmark for small \cite{mohamed_acoustic_2012} and then for large \cite{dahl_context-dependent_2012} vocabulary tasks.

Más allá del éxito obtenido en la aplicación de \glspl{cnn}--desde el año 2000--a reconocimiento de señales de tránsito \cite{ciresan_multi-column_2012}, segmentación de imágenes biológicas \cite{ning_toward_2005,turaga_convolutional_2010}, detección de rostros, texto, peatones y cuerpos humanos en imágenes naturales \cite{sermanet_pedestrian_2012,vaillant_original_1994,nowlan_convolutional_1995,garcia_convolutional_2004,osadchy_synergistic_2007,tompson_efficient_2014}, reconocimiento de rostros \cite{taigman_deepface:_2014} e independientemente de su aplicación exitosa en tecnología incluyendo robots móviles autónomos y vehículos auto-conducidos \cite{hadsell_learning_nodate,farabet_scene_2012} así como entendimiento de lenguaje natural \cite{collobert_natural_2011} y reconocimiento de habla \cite{noauthor_deep_nodate}, tales enfoques tuvieron que esperar hasta el año 2012 para ser ampliamente aceptados por la corriente principal en la comunidad de visión computacional y aprendizaje de máquinas. En la competición ImagNet--celebrada ese año--las redes neuronales convolucionales alcanzaron resultados sorprendentes, casi duplicando las performances de sus mejores rivales \cite{krizhevsky_imagenet_2012}.

%Despite of the success in the application of \glspl{cnn}--since 2000--to  traffic sign recognition \cite{ciresan_multi-column_2012}, segmentation of biological images \cite{ning_toward_2005,turaga_convolutional_2010}, detection of faces, text, pedestrians and human bodies in natural images \cite{sermanet_pedestrian_2012,vaillant_original_1994,nowlan_convolutional_1995,garcia_convolutional_2004,osadchy_synergistic_2007,tompson_efficient_2014}, face recognition  \cite{taigman_deepface:_2014} and despite of its successful applications in technology, including autonomous mobile robots and self-driving cars \cite{hadsell_learning_nodate,farabet_scene_2012} as well as natural language understanding  \cite{collobert_natural_2011} and speech recognition \cite{noauthor_deep_nodate}, those approaches had to wait until 2012 to be widely accepted by the mainstream computer-vision and machine-learning communities, when in the ImageNet competition in 2012 deep convolutional networks achieved spectacular results, almost doubling the accuracy rates respecting to the best competing approaches \cite{krizhevsky_imagenet_2012}.

En referencia a las representaciones distribuidas en el procesamiento del lenguaje, y en el contexto de corpus grandes extraídos de texto real, se entrenan redes neuronales profundas para predecir la siguiente palabra desde una cadena de palabras teniendo en cuenta el conjunto de palabras más recientes en cierta vecindad dentro de la secuencia. En ciertos casos, la única premisa es tomar en cuenta las palabras previa y siguiente en relación a la palabra que se quiere predecir. Es sorprendente que de tan simple premisas puedan emerger representaciones distribuidas semánticas tan perspicaces en las que los vectores que representan las palabras Jueves y Miércoles--por ejemplo--son muy similares, así como los vectores que representan las palabras Suecia y Noruega \cite{bengio_neural_2003}. Las características semánticas aprendidas por tales redes no las determinan humanos expertos por adelantado, por el contrario, son descubiertas de manera automática por la red neuronal.

%In reference to distributed representations in language processing, and in the context of very large corpora in real text, deep neural networks are trained to predict the next word from a chain of words by taking into account the most recent words in the neighborhood inside the sequence. Some times the only premise is to take into account the previous and the next words in relation to the word that want to be predicted. It is striking that from too simple premises can arise insightful distributed semantic representations in which the learned word vectors for Tuesday and Wednesday--for example--are very similar, as are the word vectors for Sweden and Norway  \cite{bengio_neural_2003}. Semantic features learned by such networks are not determined by experts in advance, instead, they are automatically discovered by the neural network.

Mecanismos muy sencillos implementados por \glspl{rnn} para la traducción de oraciones y la descripción automática de imágenes generan serias dudas en cuanto a la necesidad de expresiones simbólicas internas manipuladas por reglas de inferencia. En tal sentido, se resalta el hecho de que el razonamiento cotidiano podría involucrar una gran cantidad de analogía simultáneas, cada una contribuyendo con cierta medida de plausibilidad a la conclusión \cite{noauthor_metaphors_nodate,rogers_precis_2008}.

%Very simple mechanisms carried out by \glspl{rnn} for sentence translation and automatic image caption generation raised incriminating doubts about the need of internal symbolic expressions manipulated by inference rules. In that sense, it is highlighted that everyday reasoning might involve many simultaneous analogies, each contributing with plausibility to a conclusion \cite{noauthor_metaphors_nodate,rogers_precis_2008}.

\gls{lstm} es una versión mejorada de la \gls{rnn} convencional que puede ser aplicada en la implementación de sistemas de reconocimiento del habla completos \cite{graves_speech_2013} y que ha sido utilizada también en las etapas de codificación y decodificación para la traducción realizada por máquinas \cite{sutskever_sequence_2014,cho_learning_2014,bahdanau_neural_2014}. Las máquinas de Turing y las redes de memoria son versiones mejoradas de las \gls{lstm} que han sido utilizadas para tareas que normalmente requerirían razonamiento y manipulación simbólica \cite{graves_neural_2014,weston_memory_2014,weston_towards_2015}.

%\gls{lstm}--an improved version of conventional \glspl{rnn}--can be applied in the implementation of complete speech recognition systems  \cite{graves_speech_2013} and has also been used for the encoder and decoder networks at machine translation  \cite{sutskever_sequence_2014,cho_learning_2014,bahdanau_neural_2014}. Turing machines and memory networks are \gls{lstm} improvements that have been used for tasks that would normally require reasoning and symbol manipulation  \cite{graves_neural_2014,weston_memory_2014,weston_towards_2015}.

\subsection{Plausibilidad Biológica}

Aunque las \glspl{cnn} están inspiradas en ciertos fenómenos como los desarrollados por neuronas simples y complejas en la ruta visual y presentan reminiscencias de la jerarquía LGN–V1–V2–V4–IT en la ruta ventral de la corteza visual \cite{felleman_distributed_1991}, las principales líneas de desarrollo de tales herramientas han virtualmente ignorado sus contrapartes biológicas con las que se podría encontrar respaldo explicativo--al menos en parte--a los excepcionales niveles de performance obtenidos por tales mecanismos. En tal sentido y en términos de la enorme influencia generada durante los últimos años por las redes neuronales profundas supervisadas, hay investigadores que sostienen la hipótesis de que las técnicas de backpropagation podrían ser llevadas a cabo por el tejido neuronal \cite{guerguiev_towards_2017}. En dichos trabajos, el problema de asignación de crédito es explicado en términos biológicos implementando una red que--capa por capa--clusteriza información creando representaciones abstractas de categorías de dígitos numéricos. 

%Even though \glspl{cnn} are inspired by the phenomena developed by simple and complex cells in the visual pathway and is reminiscent of the LGN–V1–V2–V4–IT hierarchy in the visual cortex ventral pathway  \cite{felleman_distributed_1991}, the mainstreams in the development of such tools has virtually ignored biological counterparts as to find support which explains--at least in part--the outstanding performance of such approaches. In that sense,  and in terms of the enormous influence of deep supervised neural networks during the last years, there are researchers who support the hypothesis that backpropagation could be carried out in neural tissue \cite{guerguiev_towards_2017}. In that work, the credit assignment problem is explained in terms of biological plausibility implementing a network which--layer by layer--clusters visual information with increasing abstract representations of digit categories. 

En otra propuesta \cite{hinton_matrix_2018,sabour_dynamic_2017}, Geoffrey Hinton aborda la plausibilidad biológica con una impronta top-down resaltando algunos inconvenientes importantes en las \glspl{cnn} como la ausencia de relación de posición (traslación y rotación) de características simples que configuran características de más alto nivel y el hecho de que el mecanismo de max pooling provee una invarianza artificialmente forzada a la red, a expensas de información valiosa. Inspirado en como los gráficos de computadora construyen una imagen visual desde sus representaciones jerárquicas internas de datos geométricos, Hinton en su lugar alega que nuestro cerebro ejecuta una especie de proceso de renderizado inverso--gráficos inversos como él les llama--desde la información visual recibida por los ojos. Para Hinton nuestro cerebro extrae una representación jerárquica del mundo y trata de compararla con patrones ya aprendidos y relaciones previamente almacenadas en el cerebro. La idea principal detrás de esta teoría es que la representación de objetos en el cerebro es independiente del ángulo con el que se mire al objeto. De esta manera el cerebro cuenta con una propiedad de invarianza más naturalmente fundamentada. Esta red ha alcanzado performances a niveles de vanguardia en conjuntos de datos simples utilizando tan sólo una fracción de los ejemplos de entrenamiento que necesitaría una \gls{cnn}. En este sentido, la teoría de cápsulas se encuentra mucho más cerca de lo que el cerebro humano realiza en la práctica. Más allá de estos resultados prometedores, la implementación actual de dichas tecnología es más lenta que los modelos de aprendizaje profundo a la hora de ser entrenados. 

%In another proposal \cite{hinton_matrix_2018,sabour_dynamic_2017}, Geoffrey Hinton tries to tackle biological plausibility in a top-down fashion highlighting important drawbacks in \glspl{cnn} as the lack of pose (translational and rotational) relationship between simpler features that make up a higher level feature and the fact that max pooling provides an artificially forced invariance to the network at expenses of valuable information. Inspired by how computer graphics construct a visual image from its internal hierarchical representation of geometric data, Hinton instead alleges that our brain do kind of a reverse rendering process--inverse graphics as he calls it--from visual information received by eyes. For Hinton, our brain extracts a hierarchical representation of the world and tries to match it with already learned patterns and relationships previously stored in the brain. The main idea behind this theory is that representation of objects in the brain does not depend on view angle and in this way they have a more naturally sourced invariance property. This network has reached state-of-the-art performance in a simple data set using just a fraction of the training examples that would need a \gls{cnn}. In this sense, the capsule theory is much closer to what the human brain does in practice.  Beyond this encouraging outcome, current implementations are much slower than other modern deep learning models in order to be trained.

Continuando en esta línea de búsqueda de plausibilidad biológica, las entidades biológicas descubren la estructura del mundo sin que ningún agente externo les diga en detalle cómo hacerlo, interactuando con el mismo y recibiendo premios o castigos en el mejor de los casos--aprendizaje reforzado--mientras que en otros casos sin pista alguna más allá de la estructura estadística inherente a los datos de manera completamente no-supervisada. El aprendizaje reforzado parece conformar las condiciones a las cuales los animales se encuentran más frecuentemente expuestos. En tal sentido, para entrenar AlphaGo, una \gls{dnn} \cite{silver_mastering_2016} se utilizó una combinación de aprendizaje supervisado asistido por experiencia humana en juegos y de aprendizaje reforzado desde juegos de auto-juego. Dicha red alcanzó un 99.8\% de tasa de triunfos contra otros programas jugadores de Go, y venció al campeón europeo--jugador humano-- de Go por 5 juegos a 0. Luego, en \cite{silver_mastering_2017} AlphaGo se convirtió en su propio maestro por medio de un algoritmo basado sólo en aprendizaje reforzado. Sin datos provistos por humanos, conocimiento, guía o dominio alguno más allá de las reglas del juego, esta red neuronal fue entrenada para predecir sus propios movimientos como así también los movimientos de los AlphaGo ganadores en juegos progresivos. Esta red neuronal mejora la fuerza en la búsqueda de árbol resultando en una más alta calidad en la selección de movimientos y--por lo tanto--en un jugador más experimentado contra si mismo en cada iteración. Comenzando desde una tabla rasa, el programa Alpha Go Zero alcanzó una performance super-humana, ganando 100-0 contra el programa publicado anteriormente vencedor del campeón de Go. 

%Biological entities discover the structure of the world without being told how, interacting with it and receiving reward and punishment in the best cases--reinforcement learning--while in other cases learning without any clue beyond the statistical structure in the data itself in a completely unsupervised fashion. Reinforcement learning seems to be the conditions under which animals are most often exposed to.  In that sense, a combination of supervised learning from human expert games, and reinforcement learning from games of self-play was used to train AlphaGo, a \glspl{dnn} \cite{silver_mastering_2016} that achieved a 99.8\% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. Then, in \cite{silver_mastering_2017} AlphaGo became its own teacher by means of an algorithm based solely on reinforcement learning. Without human data, guidance or domain knowledge beyond game rules, this neural network was trained to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in each iteration. Starting tabula rasa, the new program AlphaGo Zero achieved superhuman performance, winning 100–0 against the previously published, champion-defeating AlphaGo.

Más allá del hecho de que el aprendizaje reforzado se pueda ver como un mecanismo ubicuo para los sistemas biológicos complejos, es importante resaltar que las técnicas de aprendizaje no supervisado conducen los procesos de aprendizaje de agentes biológicos en muchos casos también. En relación con esto, Jeff Hawkins et al. \cite{noauthor_why_nodate} ha desarrollado un enfoque computacional que reúne propiedades biológicas precisas desde el tejido cortical. Dicho trabajo muestra como un modelo biológico detallado de neuronas piramidales con miles de sinapsis y \gls{sdr} puede aprender transiciones de patrones y puede formar una memoria secuencial robusta \cite{noauthor_htm_nodate}. En esta red se propone que tal memoria secuencial podría configurar una propiedad universal de todo el tejido cortical. El mismo grupo se encuentra actualmente desarrollando un enfoque convincente \cite{noauthor_theory_nodate} por medio de un modelo de red que aprende la estructura de objetos a través de movimiento. En tal investigación se prevé que las células de grilla podrían conducir la adquisición de la estructura del mudo externo en la corteza de mamíferos.

%Beyond the fact that reinforcement learning could be thought as an ubiquitous mechanism in complex biological systems, it is important to highlight that unsupervised techniques could lead the learning processes in many cases in biological agents too. Regarding this, Jeff Hawkins et al. \cite{noauthor_why_nodate} have developed a computational approach which gather precise biological properties from cortical tissue. This work shows how a biologically detailed model of pyramidal neurons with thousands of synapses and \glspl{sdr} can learn transitions of patterns and can form a powerful and robust sequence memory \cite{noauthor_htm_nodate}. They propose that such form of sequence memory could be a universal property of all neocortical tissue. The same group is currently developing a compelling approach \cite{noauthor_theory_nodate} by means of a network model that learns the structure of objects through movement. In such research it is foreseen that grid cells could lead that acquisition of the structure of the world in the mammalian cortex. 

\subsection{Evidencia Comportamental de Aprendizaje Incidental en Humanos}

Una tarea fundamental para la adquisición del lenguaje, como lo es la segmentación de palabras desde el flujo acústico del habla, la pueden llevar a cabo infantes de 8 meses de edad basándose sólo en las relaciones estadísticas entre sonidos contiguos del habla. Es más, dicha segmentación de palabras se basa en aprendizaje estadístico de tan sólo 2 minutos de exposición, esto sugiere que los infantes tienen acceso a mecanismos poderosos para la computación de las propiedades estadísticas presentes en la fonética del lenguaje de entrada\cite{saffran_statistical_1996}. En este caso los infantes recibieron estímulos acústicos continuos sin pausa ni prosodia alguna de la que se pudiera inferir los límites de las palabras. La única pista fue que la probabilidad transicional entre sílabas de una misma palabra es mayor que entre sílabas pertenecientes a palabras distintas. Con tan sólo eso, los infantes fueron capaces de extraer la reglas fonotácticas de las palabras y así demostraron capacidades muy potentes de extracción fonética más allá de la dimensión gramatical y/o semántica del lenguaje humano. Dichas dimensiones estuvieron completamente ausentes para los infantes durante las pruebas, en donde los mismos adquirieron las restricciones fonotácticas del lenguaje de manera incidental.

Nuestro objetivo principal es probar la capacidad de un modelo computacional que reúne propiedades neurofisiologicas y anatómicas precisas para obtener abstracción fonética de manera completamente no supervisada. Este es un punto fundamental que demuestra la plausibilidad biológica de nuestra implementación debido a que las restricciones fonotácticas de un lenguaje humano son adquiridas de manera incidental \cite{BRENT199693,saffran_1997} y por lo tanto--bajo tales circunstancias--no se podría aceptar supervisión alguna. Nuestro modelo computacional está inspirado en la biología de la corteza de los mamíferos pero el mismo no trata de reflejar fielmente su complejidad biológica. De la misma manera en que no es necesario que un avión aletee para poder volar, ni es necesario copiar meticulosamente la biología de un ave para crear un sistema artificial altamente eficiente desde el punto de vista aerodinámico, nosotros creemos que no es necesario copiar la complejidad biológica del cerebro para crear un sistema artificial inteligente. Basta sólo con recoger aquellos aspectos neurofisiológicos y anatómicos relevantes para el procesamiento de información en el mismo.





\section{Aportes}

\begin{itemize}

\item Implementamos un modelo computacional completamente no supervisado y biológicamente inspirado que incorpora características halladas en la corteza de mamíferos. Nuestro modelo devuelve niveles de clasificación fonética similares a aquellos encontrados en enfoques profundos de clasificación de patrones de primera línea.

%\item We implemented a completely unsupervised and biologically inspired computational model which incorporates the above mentioned cortical features. Our model returns phonetic classification accuracy levels similar to those of state-of-the-art deep pattern classification approaches.

\item Implementamos nuestros algoritmos utilizando el estándard \CC14 por medio de contenedores \gls{stl} y el paradigma de orientación a objetos o \gls{oop} en un conjunto de clases interrelacionadas por herencia y composición.

%\item We implemented our algorithms in standard \CC14 using \gls{stl} containers and the \gls{oop} paradigm in a set of classes interrelated by inheritance and composition.

\item Paralelizamos el código utilizando un paradigma híbrido \gls{mpi}+\gls{omp} y usamos sistemas de archivo paralelos (\gls{mpi} I/O parallel file system).

%\item We parallelized the code by means of a hybrid \gls{mpi}+\gls{omp} paradigm and used \gls{mpi} I/O parallel file system.

\item Implementamos nuestro propio conjunto de librerías para guardar el estado del modelo en formatos de archivo compatibles con Matlab/Octave.
	
%\item We implemented our own set of libraries in order to save the model status in Matlab/Octave file formats.

\item Nuestra implementación cuenta con capacidad de reinicio en su etapa de entrenamiento donde existe total flexibilidad en término del número de procesos con los que la aplicación es reiniciada.

%\item Our implementation has Checkpoint and Restart capacity in its training stage where there is total flexibility in terms of the number of ranks with which the execution is restarted.

\item Para producir la entrada desde el flujo auditivo, seguimos en líneas generales el modelo desarrollado por Chi T. et al.~\cite{chi_2005}. Implementamos un algoritmo llamado \gls{mrstsa}. Nuestra implementación principalmente se basa en la sección cortical en \cite{chi_2005} en lugar de basarse en su parte subcortical. Implementamos este algoritmo en C y lo paralelizamos por medio de secciones paralelas en \gls{omp}.

%\item In order to produce the inputs from auditory streams we followed main guidelines from from Chi T. et al.~\cite{chi_2005}. To that end, we implemented an algorithm called \gls{mrstsa}. Our implementation follows primarily the cortical section in~\cite{chi_2005} rather than its sub-cortical counterpart. We implemented the algorithm in C and parallelized it by means of \gls{omp} parallel sections.

\item Realizamos todos los experimentos en Cooley, un cluster para análisis y visualización provisto por el Laboratorio Nacional de Argonne.

%\item We performed all computational experiments on Cooley, a visualization and analysis cluster at Argonne National Laboratory.

	\begin{itemize}
		\item Corrimos simulaciones para realizar pruebas en ciencia utilizando hasta 25 nodos (un proceso \gls{mpi} por nodo) y 8 hilos \gls{omp} por nodo/proceso. Probamos la capacidad de invarianza en las características fonéticas--en una etapa llamada \gls{el}--en varias tareas de clasificación de palabras.
			
		%\item We ran science simulations using up to 25 nodes (one \gls{mpi} rank per node) and 8 \gls{omp} threads per node/rank. We tested the phonetic feature invariance capacity of our cortical implementation--in a stage called \gls{el}--in several word classification tasks.
			
		\item Comparamos el desempeño del \gls{el} con el desempeño de las características devueltas por el algoritmo \gls{mrstsa} por medio de clasificación con \gls{svm} de las características devueltas por cada algoritmo (Fig. \ref{fig:Experiment}).
			
		%\item We compared the \gls{el} performance with the performance of the features returned by the \gls{mrstsa} algorithm by means of \gls{svm} classification of the features delivered by each algorithm (Fig. \ref{fig:Experiment}).
			
		\item Corrimos pruebas de desempaño utilizando hasta 12 nodos (un proceso \gls{mpi} por nodo) y 12 hilos \gls{omp} por proceso/nodo. Realizamos pruebas de strong y weak scaling sobre los nodos de Cooley combinando la utilización de marcas temporales y de memoria con Allinea MAP profiler \footnote{\url{https://en.wikipedia.org/wiki/Allinea_MAP}}.

		%\item We ran performance tests using up to 12 nodes (one \gls{mpi} rank per node) and 12 \gls{omp} threads per node/rank. We performed strong and weak scaling tests on Cooley nodes combining the use of time/memory marks and Allinea MAP profiler \footnote{\url{https://en.wikipedia.org/wiki/Allinea_MAP}}.

	\end{itemize}

\end{itemize}



%\section{Declaración de Originalidad}

%Statement here.


\section{Publicaciones}

Para este trabajo se ha enviado un manuscrito \cite{dematties2018} que se encuentra en proceso de revisión.

%Publications here.
