\chapter{Conclusión}

\label{ch:conclusions}

\section{Discusión de los Resultados Obtenidos}

\subsection{Adquisición de Fonética}

Los resultados obtenidos en este trabajo sostienen las hipótesis computacionales propuestas en nuestro enfoque de modelaje para imitar la invarianza y la generalización fonética incidental.
Algunas de las hipótesis ya han sido explicadas en términos de sus propiedades  \cite{hawkins_2016}, pero más específicamente en términos de sus capacidad de aprendizaje de secuencias \cite{cui_2016}.
De todas maneras, no existen precedentes de tales características neurofisiológicas probadas en tareas de clasificación como las que se llevan acabo en el presente trabajo, en las que las reglas fonotácticas se adquieren sin la aplicación de procedimientos de obtimización como retro-propagando errores por medio de \emph{descenso de gradiente}. Adicionalmente, nuestro enfoque presenta diferencias sustanciales en cuanto a sus características de implementación algorítmica. En este trabajo, las sinapsis distales proveen contribuciones individuales de valores continuos y nuestra organización anatómica micro-columnar adquiere su comportamiento fisiológico espontaneamente con el aprendizaje. También probamos tales características en una realización con cientos de columnas corticales cada una combinando varias micro-columnas con activaciones aferentes estocásticas cuyas implementaciones futuras estás destinadas a explorar simulaciones a gran escala en sistemas computacionales de alto desempeño.

Algunos modelos computacionales han sido desarrollados previamente para entender como las categorías fonéticas son adquisidas~\cite{rasanen_2012}. El objetivo en dichos trabajos ha sido principalmente explicar aspectos relevantes de la adquisición fonética, sin dar detalles en cuanto a cómo el cerebro podría proveer tales computaciones.
Lee et al. (2009), empleó aprendizaje no supervisado para clasificación de audio con \gls{cdbn_pl}~\cite{Lee:2009:UFL:2984093.2984217}. 
Los autores probaron el desempeño en clasificación de un modelo con dos capas en una tarea de clasificación de fonemas en 39 vías sobre el conjunto de datos--\gls{timit}--para varios números de oraciones de entrenamiento. 
La primera capa nunca superó el algoritmo de \gls{mfcc} que fue utilizado como entrada a la red.
Es más, en tal trabajo no se reportó el desempeño de la segunda capa ya que esta no pudo superar a la primera.
El máximo desempeño reportado para la primer capa fue del 64.4\% contra un desempeño del 79.6\% para el \gls{mfcc}.
Sólo fue posible reportar un desempeño del 80.3\% combinando ambos, el \gls{mfcc} y la primer capa en la \gls{cdbn}.

En un trabajo más reciente, la capacidad de \glspl{dmn}--una modificación de arquitectura de \glspl{dnn} alimentada en directo que utiliza la función de activación max-out--para manejar ruido ambiental fue investigada frente a diferentes clases fonéticas y para diferentes condiciones de ruido \cite{silos_2016}. En tales experimentos--con la excepción de fonemas fricativos para 15 dB \gls{snr} de Ruido Callejero--el desempeño nunca superó el 70\%. De hecho, el desempeño se vio seriamente deteriorado en presencia de ruido blanco de 15 dB \gls{snr}, resultando en una exactitud de clasificación bien por debajo del 60\% en todos los casos.

En el trabajo aquí presentado, reportamos desempeños en clasificación de--por ejemplo--90.8\% para la \gls{el} contra 78.58\% del \gls{mrstsa} para palabras trisilábicas frente a voces cambiadas (es decir, voces que nunca fueron \emph{oidas} por la \gls{el} durante el entrenamiento; Fig. \ref{fig:PLOT}). También reportamos desempeños por encima del 70\% en la \gls{el} contra un desempeño por debajo del 35\% en el \gls{mrstsa} para palabras trisilábicas frente a ruido blanco de 19.8dB \gls{snr} y desempeños bien arriba del 40\% para palabras mono y bisilábicas frente a ruido blanco de 13.8 dB \gls{snr} (Fig. \ref{fig:PLOT}). Reportamos que la \gls{el} superó al \gls{mrstsa} para todas las condiciones de prueba y que tal comportamiento se sostuvo para diferentes números de sílabas en las palabras utilizando pruebas de significación estadística (Fig. \ref{fig:PLOT1}).

Aunque este es un buen escenario, debemos de ser cuidadosos ya que no podemos ignorar diferencias experimentales importantes con respecto a los resultados arrojados por los trabajos previos. Primero, nuestro material de entrenamiento es muy diferente  al utilizado en dichos trabajos. Nosotros utilizamos corpus generados por sintetizadores de vos en lugar de corpus estandarizados como \gls{timit}.
Nuestro principal objetivo fue el de replicar adquisición fonética temprana en humanos, lo cual es logrado incidentalmente por infantes \cite{Saffran1996StatisticalLB}.
Dada la buena calidad de las voces sintetizadas por \gls{festival}  \cite{festival2014} y su flexibilidad para componer diferentes tipos de corpus--aún con palabras que no existen en ningún lenguaje--consideramos apropiada su utilización como procedimiento experimental inicial para probar nuestro enfoque en un contexto de reglas fonotácticas adquiridas incidentalmente.
Segundo, en este trabajo abordamos tareas de clasificación de palabras multililábicas en contraste con los experimentos de clasificación de fonemas llevados a cabo por las investigaciones previas, ya que estamos principalmente motivados por probar las capacidades de la dinámica secuencial de nuestro modelo para adquirir las reglas fonotácticas que subyacen los vocabularios de entrenamiento.
Finalmente, reportamos resultados de tareas de clasificación de 5 vías en contraste con tareas de clasificación de 39 vías en \cite{Lee:2009:UFL:2984093.2984217}.
Por un lado, esta última diferencia podría haber actuado en favor de nuestro enfoque considerando que es más facil clasificar una categoría entre 5 que una entre 39.
Por otro lado, es importante resaltar que los trabajos previos han estado provistos de más material de entrenamiento con más vocabularios, más hablantes, etc.
En nuestro caso, presentamos condiciones de entrenamiento más duras, ya que nuestro modelo fue entrenado con 500 palabras desde un vocabulario de solo 5 palabras pronunciadas por 10 voces.
Más allá del tamaño pequeño de la muestra, el desempeño demostrado por nuestro modelo computacional exhibe niveles significativos de generalización fonética con la capacidad de adquirir reglas fonotácticas y de generalizar a contextos ambientales novedosos. El nuestro es un escenario mucho más preciso biológicammente que aquellos establecidos por otros enfoques en los cuales sus modelos son entrenados utilizando millones de ejemplos. Nuestro modelo, por lo tanto, imita resultados experimentales que muestran como infantes de 8 meses de edad adquieren las reglas fonotácticas inmersas en el flujo auditivo de entrada con sólo 2 minutos de exposición (180 palabras en total, de un vocabulario de 4 palabras de tres sílabas) \cite{Saffran1996StatisticalLB}.

Somos conscientes que se necesitarán mas pruebas--en diferentes escenarios--con corpus diferentes y estandardizados (como \gls{timit}) para analizar más profundamente las capacidades de nuestro enfoque.
Sin embargo, nuestro objetivo principal en el presente trabajo fue el de probar la invarianza fonética secuencial exhibida por la \gls{el} bajo condiciones experimentales estrictamente controladas en las que se conocieron los niveles de ruido, reverberación y variaciones de tono con los que el estímulo se afectó de manera precisa. El material de entrenamiento para la \gls{el} solo involucró los corpus originales de 500 palabras, pero lo más importante es que la \gls{el} nunca fue expuesto--durante su entrenamiento--a los disturbios utilizados para probar el desempeño de su clasificación. El perfil experimental aplicado en este trabajo (Fig. \ref{fig:Experiment}) deja en claro que la \gls{el} es íntegramente no supervisada y que toda la supervisión se limita a los algoritmos de \gls{svm}. Más aún, la \gls{el} no optimiza la actualización de sus pesos sinápticos utilizando descenso del gradiente retro-propagando errores producidos por funciones de costo arbitrariamente insertadas. Este es un punto fundamental para demostrar la plausibilidad biológica de nuestra implementación ya que las restricciones fonotácticas en el lenguaje humano son adquiridas incidentalmente \cite{BRENT199693,saffran_1997} y por lo tanto, supervisión alguna podría ser tolerada bajo tales circunstancias comportamentales.

En futuras investigaciones, ciertas propiedades dinámicas emergentes podrían surgir de la incorpoaración de capas corticales subsecuentes--más allá de la \glsfirst{el}--en los pasos de procesamiento del modelo. De esta forma podremos implementar dendritas apicales distales hacia atrás, las cuales traerán contexto por medio de una implementación jerárquica no supervisada.
Aunque tal retroalimentación podría ser útil en el contexto de la adquisición fonética incidental, el modelado de la competencia fonética adulta podría requerir la implementación de hipótesis más complejas para nuestro modelo. La incorporación de funciones de costo con más precisión biológica para poder retroalimentar cualquier tipo de error de activación requerirá hipótesis biológicamente precisas. ¿Deberían esos errores ser señales escalares (mecanismos de refuerzo) o deberían ser vectores (mecanismos supervisados)? ¿Deberían provenir desde la misma modalidad o deberían ser traídas desde una modalidad diferente? ¿Deberían variar a través de parches corticales diferentes o deberían variar durante el desarrollo temporal? \cite{10.3389/fncom.2016.00094}.
Un mecanismo supervisado asistido por diferentes áreas corticales de forma multimodal podría ser una hipótesis biológicamente precisa ya que se ha mostrado cómo gestos icónicos impulsan la comprensión del habla bajo condiciones auditivas adversas \cite{HOLLE2010875}.
Incluso, la conectividad funcional a través de diferentes áreas corticales facilita la comprensión del habla cuando la inteligibilidad de la señal es reducida~\cite{Obleser2283}. Sin embargo, más allá de hipótesis en relación a funciones de costo, también es importante determinar los algoritmos utilizados para retroalimentar errores de activación. Independientemente del hecho de que el método de descenso de gradiente es--a primera vista--demasiado complejo para ser implementado por el tejido cortical, varios estudios sostienen la idea de que la asignación de crédito--el objetivo último en backpropagation--podría ser un fenómeno presente en el cerebro \cite{Guerguiev2017TowardsDL}. De hecho, en \cite{Lillicrap_2016} los autores presentan un mecanismo que realiza backpropagation relajando la arquitectura de conectividad en reverso y asignando responsabilidad a cada unidad multiplicando errores por pesos sinapticos aleatorios.
Más allá de todo lo mensionado, no existe prueba de que el cerebro implemente descenso de gradiente de la manera en que se implementa en redes \glspl{dnn} actuales, por lo tanto, nuevas estrategias--con más plausibilidad biológica--podrían surgir desde la comunidad científica en el futuro.

En versiones futuras del modelo se aumentará su plausibilidad biológica incrementando el número de células por \gls{cc} con simulaciones en sistemas \gls{hpc} de escalado masivo y utilizando un \gls{gsom} por \gls{cc} a los fines de incorporar reclutamiento de recursos neuronales en cada \gls{cc} dependiendo de la dispersión estadística del estímulo \cite{Meyer19113}. Por ejemplo, un arreglo tetradimensional de unidades neuronales se podría emplear para simular columnas corticales de aproximadamente 34.000 células. De esta manera, miles de columnas corticales se podrían organizar en arreglos multidimensionales. A través de la utilización de supercomputadoras de clase lider (por ejemplo, recursos posicionados en la lista del Top 500 en computación, \url{top500.org}), y asumiendo una columna cortical por nodo computacional con 64 núcleos, correríamos aproximadamente 256.000 hilos. Tales simulaciones nos permitirían elevar la capacidad de adquisición así como generalización fonética considerablemente más allá de los niveles reportados en este trabajo.


\subsubsection{Conclusión}

En este trabajo, analizamos representaciones invariantes fonotácticas secuenciales para altos niveles en la via auditiva en respuesta a estímulos de sonidos fonéticos complejos. Investigamos tales representaciones en relación a características potencialmente relevantes de la corteza auditiva. Incorporamos tales características en un modelo computacional--dentro de la etapa \gls{el} en un modelo llamado \gls{cstm}--y utilizamos clasificación por medio de \gls{svm} para probar su desempeño para varias tareas de clasificación de palabras. Comparamos el desempeño de nuestro modelo con el desempeño alcanzado por el algoritmo \gls{mrstsa}. La \gls{el} muestra capacidades de adquisición fonotáctica secuencial prominentes, superando al algoritmo \gls{mrstsa} en todas las pruebas realizadas. Debido a que el perfil experimental está diseñado para probar los niveles de generalización fonética en ambos algoritmos, exponiendo el material de entrenamiento a disturbios ambientales y a variaciones de tono, nuestro modelo muestra capacidad de generalización fonética significativa, mejorando el desempeño del \gls{mrstsa}, aún cuando este ha sido comprometido seriamente. 

En futuras investigaciones, propiedades dinámica emergentes podrían surgir de la adición de capas corticales subsecuentes--más allá del \glsfirst{el}--en las etapas de procesamiento de este modelo. De esta forma podremos implementar dendritas apicales distantes hacia atrás, las cuales proveerán contexto por medio de una implementación jerárquica no supervisada. También planeamos incorporar más plausibilidad biológica incrementando el número de células por \gls{cc} por medio de escalamiento masivo en simulaciones de \gls{hpc} y utilizando un \gls{gsom} por \gls{cc} a los fines de incorporar especialización en el reclutamiento de recursos neuronales en cada \gls{cc} dependiendo de la dispersión estadística en sus estímulos \cite{Meyer19113}.

Aunque investigación adicional futura--con más material experimental--será requerida, los hallazgos presentados aquí podrían ser influyentes delineando caminos nuevos y alternativos a las tecnologías actuales de percepción profunda en general y, más específicamente, en términos de características neurofisiológicas específicas relevantes para adquisición temprana de lenguaje por reglas fonotácticas en infantes.













\subsection{Estrategias de Paralelización}

En este trabajo mostramos cómo estrategias específicas de paralelización con gran independencia de la coalescencia de los datos escalan eficientemente en sistemas de memoria distribuida mientras corren modelos computacionales biológicamente inspirados con perfiles de conectividad altamente dispersos y aleatorios.

Las implementaciones algorítmicas fuertemente basadas en arquitecturas de computación paralela \emph{\gls{simd}} imponen restricciones importantes sobre el alineamiento de los datos en memoria.
Los hilos \gls{omp} en sistemas de memoria compartida son en cambio abstracciones altamente independientes y poderosas de procesamiento que pueden realizar tareas complejas con optimizaciones eventuales de vectorización cuando sea posible.

Nuestros hallazgos muestran que las estrategias de paralelización utilizadas en este trabajo presentan una eficiencia de escalabilidad buena y robusta aún frente a cargas intensivas de \gls{ipc}.
Tal comportamiento se puede mantener de manera sostenida siempre y cuando se conserve un balance de carga computacional mínimo entre los diferentes hilos.
En la sección~\ref{MRSTSA_Scaling_Tests} mostramos eficiencias de escalado muy altas.
Aún así advertimos acerca de las dificultades de cara a un contexto con tamaños disímiles de corpus.
Alcanzar balance en la carga en sistemas de memoria distribuida es extremadamente caro dada la cantidad de sobrecarga de \gls{ipc} requerida.
De esta forma, afirmamos que la mejor manera de balancear la carga computacional entre los elementos computacionales is tratar de confinar tanta carga computacional como sea posible en una unidad de memoria compartida sin exceder las capacidades de hilado concurrente o hiper-hilado provistas por un nodo.
Una vez que se satisfacen tales condiciones se hace relativamente simple lanzar un cierto número de hilos en los que se puede distribuir el trabajo.
Ya en un sistema de memoria compartida, los hilos \gls{omp} son mucho más ligeros que los procesos \gls{mpi}, ya que los hilos no duplican el \emph{heap} ni el programa y no necesitan métodos complejos de comunicación para compartir los datos.
Asimismo, los hilos \gls{omp} pueden manejar el balance de la carga de manera eficiente y automáticamente ya que \gls{omp} maneja planificación paralela dinámica de manera autónoma.
Esto es muy deseable, especialmente en un entorno de simulación en el que los módulos individuales--como las \gls{cc_pl} en nuestro modelo cortical--no son uniformemente análogos en términos de tamaño ni conectividad.
En \gls{mpi} en cambio, el programador se tiene que hacer cargo del balanceo de la carga utilizando \gls{ipc} de manera intensiva especialmente cuando la comunicación es entre procesos en nodos diferentes.
Por otro lado los hilos \gls{omp} sufren el fenómeno denominado \emph{false shearing} en las caches de las \gls{cpu_pl}, pero con un esquema de paralelización altamente flexible como el utilizado en la sección \ref{EL_Parallelization} el usuario puede variar la granularidad en la paralelización de manera flexible para alcanzar el mejor desempeño evitando que cada hilo exceda la cuota de memoria cache disponible en cada \gls{cpu}.

En las Figs.~\ref{fig:Corpora_Scaling}, \ref{fig:MRSTSA_Scaling}, \ref{fig:EL_Strong_Scaling} y \ref{fig:EL_Weak_Scaling} el fenómeno de \emph{super-linear speedup} se hace presente en varios casos.
En S. Ristov et al. \cite{7733347} los autores afirmaron que: \texttt{la mejora super-lineal en el desempeño en algoritmos persistentes ocurre principalmente debido al incremento de recursos de cache en arquitecturas de computadoras paralelas, el precargado de variables compartidas en la organización de memoria compartida, o una mejor planificación en entornos heterogéneos.
Los efectos de las arquitecturas de memoria compartida también impactan el desempeño del comportamiento de los algoritmos granulares y escalares.}
Nosotros apoyamos dicha moción y la consideramos una explicación general y válida para nuestro caso. Sin embargo, también consideramos que se requerirá un análisis más profundo de la utilización de la memoria haciendo uso de herramientas de profiling que se podrían requerir en el futuro.

En la sectión~\ref{EL_Parallelization} podrían surgir algunos problemas cuando una única \gls{cc} es muy grande para compartir un nodo computacional con muchas otras.
Si solo 2 \gls{cc_pl} entraran en un nodo, la granularidad en la paralelización sería muy pobre, pero los hilos \gls{omp} son altamente versátiles y pueden fácilmente  manejar hilado anidado.
En tal caso podríamos variar la granularidad de paralelización de manera extremadamente accesible con todas las ventajas de \gls{omp} en términos de balance de carga dinámica.
Esta estrategia de paralelización anidada se podría aplicar en la sección~\ref{MRSTSA_Scaling_Tests} de cara a un eventual desbalance de la carga computacional desde una distribución inequitativa del tamaño de los corpus.

Este escenario en el que la carga computacional asignada a cada sistema de memoria compartida es distribuido entre un conjunto de hilos \gls{omp} altamente livianos, flexibles y dinámicos es muy favorable en un contexto en el cual el número de \gls{cpu_pl} compartiendo memoria se incrementa año tras año especialmente en computadoras de alto desempeño.
A tal efecto y de cara a los buenos resultados devueltos por nuestros experimentos, evaluamos la implementación de estas estrategias de paralelización como válidas en supercomputadoras de alto desempeño en el futuro.

Afirmamos por lo tanto que este trabajo introduce estrategias de paralelización cuya flexibilidad y robustez son particularmente útiles en escenarios científicos computacionales ampliamente variables y biológicamente inspirados cuyos enfoques de modelización pueden variar dramáticamente en estrategias de implementación biológicamente precisas diferentes en las cuales hay estructuras de redes erráticas con perfiles de conectividad altamente dispersos y aleatorios.








\subsubsection{Conclusión}

En este trabajo mostramos una estrategia de paralelización híbrida \gls{mpi}+\gls{omp} que escala eficientemente en un sistema de memoria distribuida corriendo un enfoque computacional inspirado en la biología de la corteza de los mamíferos con un perfil de conectividad altamente disperso e irregular.
Mostramos esta eficiencia por medio de pruebas de escalado fuerte y débil en los nodos de Cooley.

La independencia de la coalescencia de los datos, la reconfiguración flexible de la granularidad, el balanceo de carga dinámicamente planificado y el procesamiento paralelo liviano en porciones de memoria compartida configuran los rasgos sobresalientes en nuestro enfoque de paralelización.

Consideramos tales características de fundamental importancia para el uso de este procedimiento de paralelización en escenarios científicos computacionales altamente variables con conjuntos de datos irregularmente estructurados hallados de manera típica en enfoques de investigación biológicamente inspirados.

Por medio de los resultados devueltos en esta rueda de pruebas estimamos la política de paralelización aquí presentada, viable para ser usada en supercomputadoras de gran desempeño en el futuro.
















\subsection{Adquisición de Gramática}

En este trabajo introducimos un modelo computacional inspirado en características específicas del tejido cortical del cerebro cuyo resultado imita mecanismos de selección de relevancia lingüística en la corteza del cerebro~\cite{Gibson1998-GIBCOS, Hagoort2005OnBB, Rego1993TheCB, 10.1371/journal.pone.0177794}.

Por medio de los resultados experimentales aquí presentados mostramos cómo la convergencia de restricciones lingüísticas desde fuentes diferentes mejoran la clasificación de las funciones gramaticales llevadas por constituyentes dentro del contexto oracional.
Por ejemplo, cuando analizamos una oración específica, ambos algoritmos pierden el sentido de número en la primer palabra (\texttt{wolves}).
Excepto para tal caso, la \gls{el} atrapa el sentido de número en el resto de los casos en los que aparecen sustantivos plurales (\texttt{ungulates} y \texttt{feeders}), mientras que word2vec continúa perdiendo el sentido de número en esos ejemplos también.
Como se puede ver en la Fig. \ref{fig:PLOT3} y desde el análisis estadístico realizado en la sección \ref{Segregated}, la \gls{el} supera significativamente a word2vec en la clasificación de sustantivos, tanto plurales como singulares.

En nuestra implementación, las restricciones de categorías gruesas de palabras desde las dendritas apicales no proveen información suficiente a la \gls{el} para realizar tal distinción.
Inicialmente nuestro grupo contempló la posibilidad de que las restricciones sintácticas provenientes desde las activaciones dendríticas laterales dentro de la secuencia de constituyentes podrían suplir la información necesitada por la \gls{el} para restringir las opciones entre las diferentes opciones de unificación.
De tal manera, la \gls{el}, tomando tales restricciones podría haber terminado activando sólo la opción más adecuada dada la información recibida.
En este ejemplo, la información desde la \glsfirst{ds} proveniente desde word2vec no alcanza para distinguir el atributo de número en los sustantivos, pero la incorporación de las restricciones sintácticas como los adjetivos precediendo los sustantivos podrían haber inclinado la probabilidad hacia el atributo plural.
Más aún, dependencias de mayor distancia como la palabra \texttt{are} en la frase \texttt{are opportunistic feeders}, podría haber influenciado la clasificación dadas las propiedades secuenciales incorporadas en la \gls{el} \cite{Cui:2016:COS:3030654.3030660}.
Como dichas restricciones sintácticas no aparecen en la primer palabra de la oración, la \gls{el}  podría haber cometido el mismo tipo de error que word2vec, y ni la \gls{ds} ni las restricciones impuestas por las categorías gruesas de palabras hubieran provisto información como para atrapar el atributo plural in el sustantivo.

A los fines de probar esta hipótesis, en la sección \ref{slc} nuestro grupo probó una versión de la \gls{el} sin ramas dendríticas laterales.
La Fig. \ref{fig:PLOT2} muestra que las dendritas laterales en nuestro modelo juegan cierto rol en la integración de la información secuencial
dada la significación estadística devuelta por los experimentos.
Pero un análisis desagregado de la Fig. \ref{fig:PLOT2}--realizado en la sección \ref{Segregated}--nos permitió concluir que la mejora en la distinción entre sustantivos singulares y plurales viene de la combinación de las restricciones aferentes y apicales, y no desde la información secuencial provista por las restricciones laterales.
Este fenómeno se puede ver en la sección \ref{Segregated}, en la cual el desempeño en la clasificación de sustantivos singulares es reducido con la incorporación de las ramas dendríticas laterales mientras que el desempeño en la clasificación de sustantivos plurales no se ve afectado significativamente.

La clasificación de verbos en la oración (\texttt{feed} y \texttt{eat}), muestra claramente la importancia de las restricciones de categorías gruesas de palabras desde las dendritas apicales \cite{shi_newborn_1999,shi_morgan_allopenna_1998,Shi1995PerceptualCO,lohmann_phonological_2017,doi:10.1207/s15327078in1002_5}.
En tal sentido, word2vec confiere un alto peso a los sustantivos en ambos ejemplos, clasificando erróneamente la palabra \texttt{feed} como sustantivo singular y dando casi la misma probabilidad (33.9\% vs. 33.3\%) a las etiquetas de verbo en forma base y sustantivo singular cuando aparece el verbo \texttt{eat}.
La \gls{el} por otro lado, desecha virtualmente la clasificación de tales verbos como sustantivos, clasificando erróneamente \texttt{feed} como verbo en forma base pero asignando una gran chance a la etiqueta correcta (la segunda más alta).
La \gls{el} también produce la clasificación correcta de \texttt{eat}, confiriendo una alta probabilidad a la etiqueta correcta.

En la sección \ref{Segregated}, la Fig. \ref{fig:PLOT3} muestra que las construcciones gramaticales para los verbos son clasificadas significativamente mejor por la \gls{el}.
La única excepción es para el caso de los verbos modales (\texttt{V\_MD}) como se puede inferir desde el análisis estadístico.
Desde la Fig. \ref{fig:PLOT4}, podemos observar que las dendritas laterales contribuyen significativamente a la clasificación de los verbos.
Desde el análisis estadístico las mejoras específicas son para los \emph{verbos no 3ra persona presente singular} (\texttt{V\_VBP}), \emph{verbos en pasado} (\texttt{V\_VBD}) y \emph{verbos en forma base} (\texttt{V\_VB}).

El caso de los adjetivos es sorprendente como se puede ver en la Fig. \ref{fig:Sentence1}.
Aunque los adjetivos \texttt{sized} y \texttt{available} son clasificados correctamente por ambos algoritmos, hay una diferencia notoria en tales clasificaciones que puede ser apreciada en la solidez con la que la \gls{el} atribuye chances a las etiqueta correcta en ambos casos.
Por un lado, word2vec presenta poca seguridad atribuyendo una muy baja probabilidad a la etiqueta correcta, especialmente en el caso de \texttt{sized}, en el que el algoritmo atribuye casi la misma probabilidad a las etiquetas adjetivo, verbo en participio pasado y sustantivo singular.
Otro ejemplo importante lo da la palabra \texttt{medium}.
Aún cuando la aparición de tal palabra cuenta como un acierto para word2vec, la realidad es que la \gls{el} produce la clasificación correcta de dicho término como adjetivo, y tal clasificación es sólida debido a la alta probabilidad asignada a la etiqueta.
Desde la Fig. \ref{fig:PLOT3}, podemos observar que la \gls{el} mejora la clasificación de los adjetivos significativamente.
La Fig. \ref{fig:PLOT4} muestra que esta mejora no viene de la contribución provista por las dendritas laterales distales.

Es importante poner en relieve algunos casos específicos para los cuales la \gls{el} construye su propio desempeño de clasificación desde un desempeño de word2vec del 0\%.
Los casos más prominentes son para las etiquetas siguientes:
\texttt{C\_TO}, con ejemplos típicos como \emph{... the voice \textbf{to} renew ...} o \emph{... released \textbf{to} radio ...} y
\texttt{CONJ\_IN}, con ejemplos típicos como \emph{... as well \textbf{as} ...} o \emph{... rather \textbf{than} ...}.
Inclusive, el desempeño de clasificación en tales casos se sostiene exclusivamente por las dendritas laterales distales como se puede inferir desde el análisis estadístico realizado en la sección \ref{Segregated}.

Para algunos adverbios como
\emph{superlativos} (\texttt{ADV\_RBS}) con ejemplos como \emph{the third \textbf{most} common ...} o \emph{his \textbf{most} serious poem ...}, \emph{conjunción subordinada} (\texttt{ADV\_IN}) con ejemplos como \emph{after wandering \textbf{around} he discover ...} o \emph{... soon \textbf{after}} y \emph{adverbios comparativos} (\texttt{ADV\_RBR}) con ejemplos como \emph{... to \textbf{better} measure future cash flow} o \emph{... her autobiography \textbf{more} important than her poetry}, el desempeño de clasificación de la \gls{el} se sostiene completamente por medio de las dendritas laterales distales.

Los adverbios (\texttt{ADV\_RB}) con ejemplos como \emph{... that is \textbf{almost} completely black} o \emph{it was released \textbf{only} in australia}; son clasificados significativamente mejor por la \gls{el} y las dendritas laterales distales--aún cuando no de manera exclusiva--contribuyen significativamente al desempeño en dicha clasificación.


Comparándola con word2vec, la \gls{el} activa menos configuraciones frasales, estrechando el espectro de candidatos alternativos de vinculación.
Asigna valores altos de probabilidad a menos etiquetas y en general tales etiquetas son las correctas o más cercanas a las correctas.
Este hecho es sostenido por la tasa más alta de la \gls{el} comparada a la de word2vec (Fig. \ref{fig:Grammar_PLOT}).

En cuanto al trabajo relacionado en el campo,  Wennekers et al. \cite{WENNEKERS200616} introdujeron un enfoque de modelación en el que redes con múltiples áreas se construyen con características anatómicamente idénticas.
De manera similar al modelo que presentamos en este trabajo, la arquitectura de tal red introduce células que incluyen conexiones directas, laterales y de retroalimentación las que son establecidas por medio de principios asociativos motivados en las reglas de Hebb \cite{doi:10.1002/1097-4679(195007)6:3<307::AID-JCLP2270060338>3.0.CO;2-K}.
En un trabajo más reciente, utilizando los mismos principios de modelación Tomasello et al. \cite{TOMASELLO2017111} desarrollaron una red neuronal artificial fisiológicamente plausible que replicó áreas sensorimotoras, multimodales y del lenguaje.
Los experimentos reportaron \emph{circuitos semánticos} emergentes para palabras relacionadas a objetos y a acciones las que exhibieron especificidad categórica en áreas con modalidad preferencial.
Aunque los resultados en ambos trabajos se puedan comparar con datos experimentales reales--merced a la faceta neurocomputacionalmente realista de los modelos--los perfiles experimentales se centraron principalmente en mediciones de correlación estadística y sobre aspectos semánticos--la gramática no formó parte del trabajo.
El aprendizaje de estructuras sintácticas no estuvo dentro del alcance de la investigación.
En general Wennekers et al. \cite{WENNEKERS200616} manifestaron que la adquisición de estructuras sintácticas es un problema de gran dificultad en esas redes.
Incluso, no se realizaron tareas de reconocimiento al estilo del \glsfirst{ml}, los corpus utilizados en los experimentos se generaron artificialmente y los modelos no se probaron en invarianza de clasificación.

Un modelo computacional que asigna roles temáticos a los constituyentes de una oración fue desarrollado previamente \cite{STJOHN1990217}.
El modelo desambigua palabras, crea instancias de palabras vagas y elabora roles implicados.
Recientemente dicho enfoque computacional se utilizó para explicar el potencial relacionado a evento N400 presentando un modelo computacional explícito para la representación emergente del significado oracional \cite{rabovsky_modelling_2018}.
El modelo capturó respuestas neuronales empíricas diversas mostrando que aspectos esenciales del procesamiento del lenguaje humano pueden ser efectivamente presentados por un marco conectivista apropiado.
Sin embargo, el modelo carecía de un mapeo de características neurofisiológicas en la dinámica cortical y utilizó algoritmos de optimización (como backpropagation) de difícil mapeo en el tejido cortical.

Dominey et al. \cite{Dominey2009NeuralNP} por otro lado, incorporó la neurofisiología funcional de la comprensión oracional (junto con procesamiento secuencial no lingüístico), en un modelo de red neuronal cuya arquitectura fue restringida por la conectividad neuroanatómica del \gls{cstc} y también por datos provinientes de imágenes funcionales. 
El modelo pudo aprender y realizar varios tipos de tareas de sintaxis artificial y lenguaje.
Su enfoque incluye la interacción entre varias \gls{ba_pl} involucradas en el procesamiento del lenguaje, tales como el \gls{ba} 47, 45 y 44/6 en el \gls{lifg}.
Sin embargo tal modelo también forzó la elección de las opciones correctas por medio de métodos de aprendizaje supervisados guiados por error.
Tal metodología asume la existencia de \emph{señales tutoras} en el cerebro. Dichas señales se necesitan para forzar la capa de salida hacia la respuesta correcta, habilitando la red a retropropagar errores.

Michalon y Baggio \cite{michalon_meaning-driven_2019} desarrollaron una implementación algorítmica explícita de una arquitectura de procesamiento paralela que explica cómo la información sintáctica y semántica puede interactuar selectivamente durante la comprensión del lenguaje.
La arquitectura avanza hacia la organización del lenguaje en el cerebro enfocándose en la articulación entre la sintaxis y la semántica y la esencia de la predicción en la comprensión del lenguaje.
El trabajo está claramente inspirado en la psicología y neurociencia del lenguaje pero no incorpora características biológicamente precisas de la computación neuronal en su implementación.

En el presente trabajo el modelo computacional desarrollado está inspirado en la biología de la corteza de los mamíferos y simula tejido cortical incorporando organización colunar, formación microcolumnar espontánea, \gls{sdr_pl} y adaptación a activaciones contextuales.
Además, se asignan diferentes roles a las configuraciones dendríticas próximas y distales simulando células piramidales.
Incorporamos importantes fenómenos anatómicos y fisiológicos tales como la consideración de ramas dendríticas como elementos de procesamiento activos e independientes, la activación estocástica de células cerebrales y \gls{mfe_pl} originados por fallas de predicción en la red manifestándose como la activación de muchas neuronas en una \gls{cc} impidiendo la formación de \gls{sdr_pl}--entre otros.
La mayoría de las \gls{ann_pl} tales como las utilizadas en trabajos previos \cite{STJOHN1990217, rabovsky_modelling_2018, Dominey2009NeuralNP, michalon_meaning-driven_2019}, utilizan neuronas artificiales sin considerar dendritas activas y con un número no realista de sinapsis, por lo tanto, pierden propiedades funcionales fundamentales en el cerebro.
Inclusive, a diferencia de los modelos computacionales establecidos, el modelo aquí presentado no incorpora métodos de optimización como aquellos hallados en algoritmos supervisados o reforzados.
Aunque influyentes líneas de investigación refuerzan la idea de la \emph{asignación de crédito} apoyando procesos de retropropagación en la corteza \cite{10.7554/eLife.22901}, hasta ahora no hay suficiente evidencia que justifique la inclusión de procesos de tal complejidad en el cerebro.
Es más, nuestra preocupación en relación a la existencia de backpropagation en el cerebro va más allá de la complejidad de su implementación algorítmica.
Dichas implementaciones requieren de la existencia de \emph{señales tutoras}.
Aunque hay evidencia de que los animales pueden representar salidas comportamentales deseadas con representaciones internas de objetivos \cite{gadagkar_dopamine_2016}, no se sabe si dichas señales en realidad existen en el cerebro.
Por otro lado, aunque enfoques algorítmicos muy novedosos y convincentes tales como BERT \cite{DBLP:journals/corr/abs-1810-04805} y GPT-2 \cite{radford_language_nodate, DBLP:journals/corr/VaswaniSPUJGKP17} están produciendo cambios significativos en el \gls{nlp} en general, ellos siguen necesitando de optimizaciones algorítmicas de difícil justificación en la corteza cerebral.
De hecho dichos enfoques aplican mecanismos como \emph{Atención} sin restricciones demandando la disponibilidad de todas las palabras en las oraciones de entrada sin proveer explicaciones claras de mecanismos de memoria para poder sostener tales fenómenos en el cerebro.

En el presente trabajo, nosotros reemplazamos las señales tutoras utilizadas por otros sistemas--especialmente requeridas por backpropagation--por la simple y uniforme correlación de activaciones \gls{sdr_pl} desde diferentes parches corticales.
Nuestra hipótesis es que cuando el ruido perjudica la individualización fluida de un patrón que viene desde cierta fuente, el cerebro correlaciona tal información con información proveniente desde otras fuentes en las que el ruido no ha sido tan perjudicial para el patrón que el agente pretende clasificar.
En el presente modelo, cuando la información de \glsfirst{ds} desde las dendritas aferentes no es suficiente para realizar la desambiguación gramatical de un constituyente oracional, la información de categorías gruesas de palabras desde las dendritas apicales ayudan en tal desambiguación.
En el caso en que las pistas provistas por las categorías gruesas de palabras no puedan compensar la falta de información de \gls{ds}, las restricciones sintácticas desde las dendritas laterales resultarían de ayuda.
La conectividad funcional a través de diferentes áreas corticales ha mostrado facilitar la comprensión del habla cuando la inteligibilidad de la señal de habla es reducida ~\cite{Obleser2283}.

Por otro lado la presencia de conectividad recíproca entre diferentes áreas como así también la conectividad recurrente dentro del mismo área es un patrón recurrente en la corteza.
La ausencia de conectividad anatómica recíproca y/o recurrente entre algunas áreas corticales en nuestras simulaciones tiene sus ríces en la implementación actual de nuestro modelo.
Debido a que la \gls{ds} es provista por word2vec, no tenemos la posibilidad de inyectar señales hacia atrás desde la \gls{el} ni tampoco de implementar conectividad recurrente dentro de tal modelo.
En el caso de las categorías gruesas de palabras, sus \gls{sdr_pl} son estáticas y no pueden ser enriquecidas por conectividad recurrente ni por señales hacia atrás desde la \gls{el}.

En esta investigación utilizamos algunas características del gradiente de procesamiento de información descubierto en el \gls{lifg} como guía para explicar una interacción plausible entre diferentes restricciones léxicas en la corteza.
En esta región compleja de la corteza, la información proveniente desde las \gls{ba_pl} 47 y 45 está involucrada en procesamiento semántico \cite{GOUCHA2015294, DECARLI2007933, PMID:15528098, NEWMAN201051} y la utilizamos como la puerta de entrada de la \gls{ds} a la \gls{el}.
Es importante resltar sin embargo que hay rutas alternativas--más allá del \gls{ba} 47--en la que se procesa la información semántica
como los lóbulos parietales temporal e inferior--entre otras áreas \cite{Binder2011TheNO}.

De hecho, muchas otras fuentes de información--las cuales resultan ser útiles para adquisición del lenguaje--aún no han sido consideradas en nuestro enfoque computacional.
Por ejemplo se ha mostrado que los gestos icónicos amplifican la comprensión del habla bajo condiciones auditivas adversas \cite{HOLLE2010875}.
Estudios neurocognitivos de representaciones motoras de los sonidos del habla, del lenguaje relacionado a acciones y gestos de respuesta durante la conversación se encuentran muy relacionados al sistema del lenguaje \cite{Willems2007NeuralEF}.
El trabajo futuro en este modelo estará dirigido a la integración de información desde más fuentes que las utilizadas hasta ahora.
También en un futuro enrriqueceremos la información de categorías gruesas de palabras proveniente desde las dendritas apicales con información fonológica directa para producir una integración linguística más holística.
Con dicha implementación vamos a poder aplicar conectividad hacia atrás posiblemente derivada desde las \gls{ba_pl} 45/44 al \gls{ba} 6 y también de incluir conectividad recurrente en etapas específicas del modelo relacionadas a sintáxis gruesa y fonología.
Finalmente en desarrollos futuros de este trabajo incorporaremos mecanismos de refuerzo al modelo incluyendo efectos neuro-modulatorios en el algoritmo los cuales podrían mejorar el desempeño de manera significativa.











\subsubsection{Conclusión}

Esta investigación trae una explicación novedosa de cómo la activación cortical para las restricciones lingüísticas podría producir discriminación gramática emergente en los constituyentes oracionales desde la interacción de áreas específicas en el cerebro humano.
Dichas áreas presentan un gradiente de procesamiento lingüístico el que se mapea precisamente en la dinámica  cortical de un modelo computacional que simula características particulares evaluadas como apropiadas para realizar computaciones lingüísticas en la corteza cerebral de los humanos.
Introducimos un modelo computacional biológicamente plausible que incorpora características específicas traídas desde la corteza de los mamíferos.
Nuestro modelo utiliza reglas Hebbianas sin involucrar mecanismos de optimización extensamente utilizados en algoritmos de \gls{ml} predominantes, pero de difícil justificación en el tejido cortical.
Utilizamos tal modelo para explicar operaciones de unificación a niveles semántico y sintáctico del lenguaje en el área cortical correspondiente al \glsfirst{lifg}.
Mostramos cómo las activaciones corticales en las propiedades de \glsfirst{sdr_pl} devueltas por nuestro modelo sostienen la clasificación de funciones gramaticales léxicas de palabras desde las propiedades de \glsfirst{ds} devueltas por word2vec. 
Evaluamos que esta investigación tiene valor para futuras aplicaciones del \gls{ml} al \gls{nlp} con más inspiración en el cerebro así como también una validación complementaria para las teorías psico-lingüísticas del procesamiento del lenguaje.

































%Los resultados obtenidos en el presente trabajo respaldan la hipótesis de que ciertas características neuroanatómicas y fisiológicas--principalmente en el tejido cortical--podrían ser cruciales para la invarianza en la percepción fonética auditiva. Estas características ya han sido explicadas en términos de sus propiedades \cite{hawkins_2016}, pero más específicamente en términos de su capacidad para adquirir patrones secuenciales \cite{cui_2016}. De todas maneras, no existen precedentes de tales características neurofisiológicas probadas en tares de clasificación de palabras como las que se han llevado a cabo aquí. Adicionalmente, nuestro enfoque presenta diferencias sustanciales en términos de la implementación algorítmica de tales características. En el presente trabajo, las sinapsis distantes producen contribuciones individuales y nuestra organización micro-columnar anatómica adquiere su comportamiento fisiológico de manera espontánea con el aprendizaje. En este trabajo también se testean tales características en una realización con cientos de columnas corticales cada una combinando varias micro-columnas con activación aferente estocástica cuyas implementaciones futuras están dirigidas a la explotación de recursos computacionales en simulaciones de gran escala en supercomputadoras. 

%%Results obtained in the present work support the hypothesis that certain neuroanatomical and neurophysiological features--mainly in cortical tissue--might be crucial for auditory perceptual phonetic invariance. These features have already been explained in terms of their properties \cite{hawkins_2016}, but more specifically in terms of their sequence learning capabilities \cite{cui_2016}. Nevertheless, there are no precedents of such neurophysiological features tested in word classification tasks as the ones carried out here. In addition, our approach presents substantial differences in terms of feature algorithmic implementation. In the present work, distal synapses make continuous individual contributions and our anatomical micro-columnar organization acquires its physiological behavior spontaneously from learning. We also tested such features in a realization with hundreds of cortical columns each combining several micro-columns with stochastic afferent activation whose future implementations are intended to explode large-scale simulations in leadership supercomputers (see section \nameref{Comp_setup}).

%Existen modelos computacionales que han sido desarrollados previamente para entender cómo las categorías fonéticas son adquiridas \cite{rasanen_2012}. El objetivo de dichos trabajos ha sido principalmente explicar aspectos relevantes de la adquisición fonética, sin dar detalles de cómo el cerebro podría proveer tales computaciones. Lee et al. (2009), empleó aprendizaje no supervisado de características para clasificación de audio con \glspl{cdbn}~\cite{Lee:2009:UFL:2984093.2984217}. Los autores probaron el desempeño de un modelo con dos capas para una tarea de clasificación fonética de 39 categorías sobre los datos \gls{timit} para varios números de oraciones de entrenamiento. La primer capa nunca superó el algoritmo \gls{mfcc} que se utilizó como entrada a la red. Además, tal trabajo no reportó el desempeño de la segunda capa debido q que la misma no pudo superar la primera. El desempeño máximo reportado para la primer capa fue del 64.4\% contra un desempeño del 79.6\% para el \gls{mfcc}. Sólo se pudo reportar un desempeño del 80.3\% combinando ambas capas, el \gls{mfcc} y la primer capa del \gls{cdbn}.

%%Computational models have been previously developed to understand how phonetic categories are acquired~\cite{rasanen_2012}. The goal in these works has been mainly to explain relevant aspects of phonetic acquisition, without details about how the brain might provide such computations. Lee et al. (2009), employed unsupervised feature learning for audio classification with \glspl{cdbn}~\cite{Lee:2009:UFL:2984093.2984217}. The authors tested classification performance of a model with two layers in a 39-way phone classification accuracy task on the test data \gls{timit} for various numbers of training sentences. The first layer never outperformed the \gls{mfcc} algorithm that was used as input for the network. Furthermore, such work did not report the second layer performance since it could not outperform the first one. The maximum performance reported for the first layer was 64.4\% vs. a performance of 79.6\% for the \gls{mfcc}. It was just possible to report a performance of 80.3\% by means of combining both, the \gls{mfcc} and the first layer in the \gls{cdbn}.

%En un trabajo más reciente la capacidad de \glspl{dmn}--una modificación de la arquitectura \glspl{dnn} feed-forward que usa la función de activación max-out--para manejar ruido ambiental fue investigada para diferentes clases fonéticas y para diferentes condiciones de ruido \cite{silos_2016}. En tales experimentos--con excepción de los fonemas fricativos para 15 dB de \gls{snr} en ruido de calle--el desempeño nunca superó el 70\%. Además, el desempeño se vio seriamente comprometido en presencia de ruido blanco de 15 dB \gls{snr}, resultando en un desempeño de clasificación bien por debajo del 60\% in todos los casos. 

%%In a more recent work, the capacity of \glspl{dmn}--a modification of \glspl{dnn} feed-forward architecture that uses a max-out activation function--to handle environmental noise was investigated into different broad phonetic classes and for different noise conditions \cite{silos_2016}.  In such experiments--with the exception of fricatives phonemes for 15 dB \gls{snr} Street Noise--accuracy never exceeded 70\%. Furthermore, performance was seriously impaired in the presence of 15 dB \gls{snr} white noise, resulting in classification accuracy  well below 60\% in all cases.

%En el presente trabajo, reportamos desempeños de clasificación de--por ejemplo--97.2\% en el \gls{el} contra un 52.4\% para el \gls{mrstsa} para palabras trisilábicas para ruido blanco de 19.8 dB \gls{snr} (Fig. \ref{fig:TRI_ACC}) y desempeños de clasificación bien por arriba de 40\% para palabras mono y bisilábicas frente a ruido blanco de 13.8 dB \gls{snr} (Figs. \ref{fig:MONO_ACC} y \ref{fig:TRI_ACC}). También reportamos que el \gls{el} superó al \gls{mrstsa} bajo todas las condiciones de prueba (Fig. \ref{fig:AV_ACC})  y que dicho comportamiento se sostuvo para diferente número de sílabas en las palabras para los vocabularios utilizados en esta tanda de experimentos (Fig. \ref{fig:AV_ACC}).

%%In the present work, we reported classification performances of--for example--97.2\% on the \gls{el} vs. 52.4\% on the \gls{mrstsa} for trisyllabic words against 19.8 dB \gls{snr} white noise (Fig. \ref{fig:TRI_ACC}) and performances well above 40\% for mono and trisyllabic words against 13.8 dB \gls{snr} white noise (Figs. \ref{fig:MONO_ACC} and \ref{fig:TRI_ACC}). We also reported that the \gls{el} outperformed the \gls{mrstsa} for all the test conditions (Fig. \ref{fig:AV_ACC}) and that this behavior was sustained through different number of syllables in the words for the vocabularies used in this research (Fig. \ref{fig:AV_ACC}).

%Aunque estos resultados son entusiasmante debemos prestar atención a las diferencias experimentales de nuestra investigación comparada con las investigaciones previas. Primero, nuestro material de entrenamiento es muy diferente al presentado en los trabajos previos. En nuestro caso utilizamos corpus generados por sintetizadores de voz en vez de corpus estandardizados como \gls{timit}. Dada la alta calidad de las voces sintetizadas por \gls{festival} \cite{festival2014} y su flexibilidad para componer diferentes tipos de corpus--aún con palabras que no existen en ningún lenguaje--consideramos como apropiado utilizar tal recurso como un procedimiento experimental inicial para probar nuestro modelo. Segundo, afrontamos tareas de clasificación de palabras multisilábicas en contraste a la clasificación de fonemas en los experimentos llevados a cabo en investigaciones previas, debido a que nuestro grupo está determinado a poner bajo prueba las capacidades secuenciales dinámicas de nuestro modelo para adquirir las reglas fonotácticas detrás de los vocabularios de entrenamiento. Finalmente, reportamos resultados de tareas de clasificación en 5 categorías vs. el desempeño en clasificación para 39 categorías en \cite{Lee:2009:UFL:2984093.2984217}. Por una parte, esta última diferencia podría haber actuado en favor de nuestro enfoque considerando el hecho de que es más fácil clasificar una categoría entre 5 que una entre 39. Por otro lado, es importante resaltar que los trabajos previos han tenido un entrenamiento mucho más extendido con más vocabularios, más voces, etc. En nuestro caso, presentamos condiciones de entrenamiento más dificultosas ya que nuestro modelo fue entrenado con 500 palabras de un vocabulario de tan sólo 5 palabras fonadas por 10 voces diferentes. Más allá de esta muestra pequeña, el desempeño obtenido por nuestro modelo neurocomputacional exhibe un nivel de generalización fonética significativo con la capacidad de adquirir reglas fonotácticas y de generalizar en contextos ambientales novedosos. 

%%Although this is a compelling scenario, we have to be cautious since we cannot ignore important experimental differences from previous research results. First, our training material was very different from that found in previous works. We used corpora generated by synthesized voices instead of standardized \gls{timit} corpora. Given the high quality of the voices synthesized by \gls{festival} \cite{festival2014} and its flexibility in order to compose different kind of corpora--even with words that do not exist in any language--we considered that this was an appropriate initial experimental procedure to test our approach. Second, we pursued multisyllabic words classification tasks in contrast to the phone classification experiments carried out in previous research, since we mainly aimed to test the dynamic sequential capability of our model to acquire the phonotactic rules behind the training vocabularies. Finally, we reported results on 5-way classification tasks vs. performance on 39-way classification tasks in \cite{Lee:2009:UFL:2984093.2984217}. On the one hand, this last difference may have acted in favour of our approach considering that it is easier to classify one category among 5 than one among 39. On the other hand, it is important to highlight that previous works have had more extended training material with more vocabularies, more speakers, etc. In our case, we presented more difficult training conditions, since our model was trained with 500 words from a vocabulary of just 5 words uttered by 10 voices. Despite the small sample size, the performance obtained by our neurocomputational model exhibits a significant level of phonetic generalization with the capacity to acquire phonotactic rules and to generalize to novel environmental contexts.

%Somos conscientes de la necesidad de más pruebas--en diferentes escenarios--con corpus estandardizados diferentes (como \gls{timit}) a los fines de poder analizar cabalmente las capacidades de nuestro enfoque. Sin embargo, nuestro objetivo principal en este trabajo fue el de probar la invarianza fonética secuencial exhibida por el \gls{el} bajo condiciones experimentales estrictamente controladas en las cuales conocíamos precisamente los niveles de ruido, reverberación y variaciones de tono con los cuales los estímulos fueron afectados. El material de entrenamiento para el \gls{el} incluyó sólo el corpus original de 500 palabras, pero aún más importante es el hecho de que ni el \gls{el} ni los clasificadores \gls{svm} fueron expuestos--durante sus entrenamientos--a las perturbaciones usadas para probar su desempeño en clasificación. El perfil de experimentación aplicado a este trabajo (Fig. \ref{fig:Experiment}) deja claro que el \gls{el} es completamente no supervisado y que toda la supervisión está limitada al algoritmo de \gls{svm}. Este es un hecho fundamental para demostrar la plausibilidad biológica de nuestra implementación ya que las restricciones fonotácticas en el lenguaje humano son adquiridas incidentalmente \cite{BRENT199693,saffran_1997} y por lo tanto, no hay lugar a supervisión alguna bajo tales condiciones.

%%We are aware that more tests--in different scenarios--with different and standardized corpora (such as \gls{timit}) will be needed to analyze the capacities of our approach more deeply. Nevertheless, our main objective in the present work was to assess the sequential phonetic invariance exhibited by the \gls{el} under strictly controlled experimental conditions in which we precisely knew the levels of noise, reverberation and pitch variations with which the stimulus was affected. The \gls{el} training material included only the original corpora with 500 words, but more importantly, the \gls{el} was never exposed--during learning--to the disturbances used to test its classification performance. The experimental profile applied in this work (Fig. \ref{fig:Experiment}) makes it clear that the \gls{el} is completely unsupervised and that all supervision is limited to the \gls{svm} algorithm. This is a fundamental point to demonstrate the biological plausibility of our implementation since phonotactic constraints in a human language are learned incidentally \cite{BRENT199693,saffran_1997} and therefore, no supervision could be supported under such behavioral circumstances.


%\section{Trabajo Futuro}

%En futuras investigaciones, planeamos enriquecer las representaciones \gls{mrstsa} de nuestro modelo  desvinculando la sensibilidad de simetría y ancho de banda, incorporando un ventaneo temporal de múltiple resolución más sofisticado y un banco de filtro coclear más biológico como así también agregando codificación del nivel de sonido y características fisiológicas sub-corticales presentes en el núcleo coclear para agregar más selectividad de frecuencia. 

%%In future research, we plan to enrich our model's \gls{mrstsa} representation by unlinking symmetry and bandwidth sensitivity, incorporating a more sophisticated multiresolution temporal windowing and a more biological cochlear filter bank, as well as adding sound level codification and also sub-cortical physiological characteristics present in the cochlear nucleus to add more frequency selectivity.

%Además, propiedades emergentes podrían surgir de la adición de capas corticales subsecuentes--más allá del \glsfirst{el}--en la jerarquía de procesamiento del modelo. De esta manera podremos implementar conexiones distantes hacia atrás provenientes de ramificaciones dendríticas apicales las que traerán contexto a la implementación jerárquica no supervisada. Tambiém planeamos incorporar más plausibilidad biológica incrementando el número de células por \gls{cc} por medio del escalado masivo en simulaciones en \gls{hpc} y utilizando un \gls{gsom} por \gls{cc} para incorporar reclutamiento de recursos neuronales especializados en cada \gls{cc} dependientes de la dispersión estadística de sus estímulos \cite{Meyer19113}. Por ejemplo, un arreglo tetradimensional de unidades neuronales se podría usar para simular columnas corticales de aproximadamente 34000 células. De esta manera, miles de columnas corticales se podrían organizar en arreglos multidimensionales. Utilizando recursos computacionales de alto desempeño (como las computadoras ubicadas en el Top 500, \url{top500.org}), y asumiendo una columna cortical por nodo con 64 cores, podríamos estar corriendo 527 unidades neuronales por hilo de ejecución en una CPU. Además, configurando un arreglo tridimensional de 1000 columnas corticales por capa cortical, un modelo de 4 capas podría estar corriendo aproximadamente 256000 hilos. Tales simulaciones podrían devenir en una mejora de la adquisición fonotáctica así como en una mejora en las capacidades de generalización más allá de los niveles reportados en este trabajo.

%%In addition, emergent dynamic properties could arise from the addition of subsequent cortical layers--beyond the \glsfirst{el}--in the processing pipeline of this model.  In this way we will be able to implement backward distal apical dendrites, which will bring context through an unsupervised hierarchical implementation. We are also planning to add more biological plausibility by means of increasing the number of cells per \gls{cc} with massively scaling \gls{hpc} simulations and using a \gls{gsom} per \gls{cc} in order to incorporate neural resource recruitment specialization in each \gls{cc} depending on the statistical dispersion of its stimuli \cite{Meyer19113}. For instance, a four-dimensional array of neural units can be employed to simulate cortical columns of approximately 34,000 cells. In this way, thousands of cortical columns can be organized in multidimensional arrays. Using a leadership-class supercomputer (e.g. resources from the Top 500 computing list, \url{top500.org}), and assuming one cortical column per compute node with 64 cores, we could be running 527 neural units per thread in a CPU. Furthermore, configuring a three-dimensional array of 1000 cortical columns per cortical layer, a model of 4 layers could be running on approximately 256,000 threads. Such simulations could allow us to leverage phonotactic acquisition as well as phonetic generalization capacities beyond the levels reported in this paper.

\section{Conclusiones Generales}

En el trabajo de tesina aquí presentado hemos construido modelos computacionales inspirados en ciertas características específicas de la corteza de los mamíferos; como ser, organización columnar, formación microcolumnar espontánea, \glsfirst{sdr_pl} derivadas de las depolarizaciones dendríticas parciales \gls{nmda}, adaptación por medio de activaciones contextuales, compartimentalización dendrítica, \glsfirst{mfe_pl} como resultado de fallas de predicción y activaciones columnares estocásticas entre otras. 
Por medio de experimentos realizados con nuestros modelos hemos mostrado cómo algunas de estas características se desempeñan con eficacia a la hora de llevar a cabo ciertas taréas linguísticas de interés.
Consideramos que este trabajo podría inspirar futuros desarrollos en el \glsfirst{ml} que observen más las características corticales aquí analizadas.
Si bien nuestros análisis han sido basados en el lenguaje, fundamentándonos en la uniformidad de la organización de la corteza cerebral de los mamíferos, creemos que los mismos rasgos corticales podrían probase para otras tareas humanas--o animales--típicas ya sean estas perceptuales o cognitivas en modalidades diferentes a las aquí analizadas.

%%CO\textsubscript{2} Maecenas convallis mauris sit amet sem ultrices gravida. Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque. Quisque augue sem, tincidunt sit amet feugiat eget, ullamcorper sed velit. 

%%Sed non aliquet felis. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Mauris commodo justo ac dui pretium imperdiet. Sed suscipit iaculis mi at feugiat. Ut neque ipsum, luctus id lacus ut, laoreet scelerisque urna. Phasellus venenatis, tortor nec vestibulum mattis, massa tortor interdum felis, nec pellentesque metus tortor nec nisl. Ut ornare mauris tellus, vel dapibus arcu suscipit sed. Nam condimentum sem eget mollis euismod. Nullam dui urna, gravida venenatis dui et, tincidunt sodales ex. Nunc est dui, sodales sed mauris nec, auctor sagittis leo. Aliquam tincidunt, ex in facilisis elementum, libero lectus luctus est, non vulputate nisl augue at dolor. For more information, see \nameref{S1_Appendix}.

%A través de simulaciones computacionales hemos demostrado que nuestra implementación de un modelo cortical mejora el desempeño en tareas de clasificación de palabras bajo condiciones ambientales específicas (como ruido blanco y reverberación) y para ciertas variaciones aplicadas a los estímulos auditivos (como corridas de tono). También demostramos la efectividad en la clasificación de palabras multisilábicas, lo cual sugiere que nuestra implementación de dinámica predictiva neurofisiológica más patrones de activación dispersos y estocásticos superan al algoritmo \gls{mrstsa} en términos de invariaza secuencial fonotáctica para las perturbaciones aplicadas a la señal de audio. Dado estos resultados, postulamos que las propiedades neuroanatómicas y neurofisiológicas incorporadas en nuestro modelo son potencialmente relevantes para el diseño de sistemas de inteligencia artificial y que podrían llegar a alcanzar niveles de invarianza y generalización fonética superiores a aquellos alcanzados por las arquitecturas actuales de aprendizaje profundo. 

%%We demonstrate via a computational simulation that our implementation of the cortical model leverages the performance in word classification tasks under specific environmental conditions (e.g., white noise and reverberation) and for certain variances applied to the auditory stimuli (e.g., pitch variations). We also demonstrate effectiveness in classifying multisyllabic words, which suggests that our implementation of neurophysiological predictive dynamics plus stochastic sparse patterns of activation outperforms the MRSTSA algorithm in terms of phonotactic sequential invariance for disturbances applied to the audio signal. Given these promising results, we posit that neurophysiological and anatomical properties in our model are potentially relevant to the design of artificial intelligence systems and may achieve higher levels of phonetic invariance and generalization than the ones achieved by current deep learning architectures.


%In this paper, we analyze the sequential phonotactic invariant representations of high levels auditory pathway responses to complex phonetic sound stimuli.  We research such representations in relation to potentially relevant features in the auditory cortex. We incorporate such features in a computational model--inside the \gls{el} stage of a model called \gls{cstm}--and use \gls{svm} classification to test its performance for several word classification tasks. We compare our model performance with the performance achieved by the \gls{mrstsa} algorithm. The \gls{el} shows prominent sequential phonotactic acquisition capabilities, outperforming the \gls{mrstsa} algorithm for all the tests performed. Since the experimental profile is designed to asses the level of phonetic generalization on both algorithms, exposing the training material to environmental and pitch disturbances not present during learning, our model shows significant phonetic generalization capacity, leveraging the performance of the \gls{mrstsa}--even when it is seriously impaired. 

%In future research, we plan to enrich our model's \gls{mrstsa} representation by unlinking symmetry and bandwidth sensitivity, incorporating a more sophisticated multiresolution temporal windowing and a more biological cochlear filter bank, as well as adding sound level codification and also sub-cortical physiological characteristics present in the cochlear nucleus to add more frequency selectivity.

%Although future research with more experimental material will be needed, the research findings presented herein will be influential in terms of drawing new and alternative paths to current deep perception technologies in general and, more specifically, towards specific neurophysiological features plausibly relevant for phonotactic infant language acquisition.






