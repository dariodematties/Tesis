\chapter{Conclusión}

\label{ch:conclusions}

\section{Resumen de los Resultados Obtenidos}

Los resultados obtenidos en el presente trabajo respaldan la hipótesis de que ciertas características neuroanatómicas y fisiológicas--principalmente en el tejido cortical--podrían ser cruciales para la invarianza en la percepción fonética auditiva. Estas características ya han sido explicadas en términos de sus propiedades \cite{hawkins_2016}, pero más específicamente en términos de su capacidad para adquirir patrones secuenciales \cite{cui_2016}. De todas maneras, no existen precedentes de tales características neurofisiológicas probadas en tares de clasificación de palabras como las que se han llevado a cabo aquí. Adicionalmente, nuestro enfoque presenta diferencias sustanciales en términos de la implementación algorítmica de tales características. En el presente trabajo, las sinapsis distantes producen contribuciones individuales y nuestra organización micro-columnar anatómica adquiere su comportamiento fisiológico de manera espontánea con el aprendizaje. En este trabajo también se testean tales características en una realización con cientos de columnas corticales cada una combinando varias micro-columnas con activación aferente estocástica cuyas implementaciones futuras están dirigidas a la explotación de recursos computacionales en simulaciones de gran escala en supercomputadoras. 

%Results obtained in the present work support the hypothesis that certain neuroanatomical and neurophysiological features--mainly in cortical tissue--might be crucial for auditory perceptual phonetic invariance. These features have already been explained in terms of their properties \cite{hawkins_2016}, but more specifically in terms of their sequence learning capabilities \cite{cui_2016}. Nevertheless, there are no precedents of such neurophysiological features tested in word classification tasks as the ones carried out here. In addition, our approach presents substantial differences in terms of feature algorithmic implementation. In the present work, distal synapses make continuous individual contributions and our anatomical micro-columnar organization acquires its physiological behavior spontaneously from learning. We also tested such features in a realization with hundreds of cortical columns each combining several micro-columns with stochastic afferent activation whose future implementations are intended to explode large-scale simulations in leadership supercomputers (see section \nameref{Comp_setup}).

Existen modelos computacionales que han sido desarrollados previamente para entender cómo las categorías fonéticas son adquiridas \cite{rasanen_2012}. El objetivo de dichos trabajos ha sido principalmente explicar aspectos relevantes de la adquisición fonética, sin dar detalles de cómo el cerebro podría proveer tales computaciones. Lee et al. (2009), empleó aprendizaje no supervisado de características para clasificación de audio con \glspl{cdbn}~\cite{Lee:2009:UFL:2984093.2984217}. Los autores probaron el desempeño de un modelo con dos capas para una tarea de clasificación fonética de 39 categorías sobre los datos \gls{timit} para varios números de oraciones de entrenamiento. La primer capa nunca superó el algoritmo \gls{mfcc} que se utilizó como entrada a la red. Además, tal trabajo no reportó el desempeño de la segunda capa debido q que la misma no pudo superar la primera. El desempeño máximo reportado para la primer capa fue del 64.4\% contra un desempeño del 79.6\% para el \gls{mfcc}. Sólo se pudo reportar un desempeño del 80.3\% combinando ambas capas, el \gls{mfcc} y la primer capa del \gls{cdbn}.

%Computational models have been previously developed to understand how phonetic categories are acquired~\cite{rasanen_2012}. The goal in these works has been mainly to explain relevant aspects of phonetic acquisition, without details about how the brain might provide such computations. Lee et al. (2009), employed unsupervised feature learning for audio classification with \glspl{cdbn}~\cite{Lee:2009:UFL:2984093.2984217}. The authors tested classification performance of a model with two layers in a 39-way phone classification accuracy task on the test data \gls{timit} for various numbers of training sentences. The first layer never outperformed the \gls{mfcc} algorithm that was used as input for the network. Furthermore, such work did not report the second layer performance since it could not outperform the first one. The maximum performance reported for the first layer was 64.4\% vs. a performance of 79.6\% for the \gls{mfcc}. It was just possible to report a performance of 80.3\% by means of combining both, the \gls{mfcc} and the first layer in the \gls{cdbn}.

En un trabajo más reciente la capacidad de \glspl{dmn}--una modificación de la arquitectura \glspl{dnn} feed-forward que usa la función de activación max-out--para manejar ruido ambiental fue investigada para diferentes clases fonéticas y para diferentes condiciones de ruido \cite{silos_2016}. En tales experimentos--con excepción de los fonemas fricativos para 15 dB de \gls{snr} en ruido de calle--el desempeño nunca superó el 70\%. Además, el desempeño se vio seriamente comprometido en presencia de ruido blanco de 15 dB \gls{snr}, resultando en un desempeño de clasificación bien por debajo del 60\% in todos los casos. 

%In a more recent work, the capacity of \glspl{dmn}--a modification of \glspl{dnn} feed-forward architecture that uses a max-out activation function--to handle environmental noise was investigated into different broad phonetic classes and for different noise conditions \cite{silos_2016}.  In such experiments--with the exception of fricatives phonemes for 15 dB \gls{snr} Street Noise--accuracy never exceeded 70\%. Furthermore, performance was seriously impaired in the presence of 15 dB \gls{snr} white noise, resulting in classification accuracy  well below 60\% in all cases.

En el presente trabajo, reportamos desempeños de clasificación de--por ejemplo--97.2\% en el \gls{el} contra un 52.4\% para el \gls{mrstsa} para palabras trisilábicas para ruido blanco de 19.8 dB \gls{snr} (Fig. \ref{fig:TRI_ACC}) y desempeños de clasificación bien por arriba de 40\% para palabras mono y bisilábicas frente a ruido blanco de 13.8 dB \gls{snr} (Figs. \ref{fig:MONO_ACC} y \ref{fig:TRI_ACC}). También reportamos que el \gls{el} superó al \gls{mrstsa} bajo todas las condiciones de prueba (Fig. \ref{fig:AV_ACC})  y que dicho comportamiento se sostuvo para diferente número de sílabas en las palabras para los vocabularios utilizados en esta tanda de experimentos (Fig. \ref{fig:AV_ACC}).

%In the present work, we reported classification performances of--for example--97.2\% on the \gls{el} vs. 52.4\% on the \gls{mrstsa} for trisyllabic words against 19.8 dB \gls{snr} white noise (Fig. \ref{fig:TRI_ACC}) and performances well above 40\% for mono and trisyllabic words against 13.8 dB \gls{snr} white noise (Figs. \ref{fig:MONO_ACC} and \ref{fig:TRI_ACC}). We also reported that the \gls{el} outperformed the \gls{mrstsa} for all the test conditions (Fig. \ref{fig:AV_ACC}) and that this behavior was sustained through different number of syllables in the words for the vocabularies used in this research (Fig. \ref{fig:AV_ACC}).

Aunque estos resultados son entusiasmante debemos prestar atención a las diferencias experimentales de nuestra investigación comparada con las investigaciones previas. Primero, nuestro material de entrenamiento es muy diferente al presentado en los trabajos previos. En nuestro caso utilizamos corpus generados por sintetizadores de voz en vez de corpus estandardizados como \gls{timit}. Dada la alta calidad de las voces sintetizadas por \gls{festival} \cite{festival2014} y su flexibilidad para componer diferentes tipos de corpus--aún con palabras que no existen en ningún lenguaje--consideramos como apropiado utilizar tal recurso como un procedimiento experimental inicial para probar nuestro modelo. Segundo, afrontamos tareas de clasificación de palabras multisilábicas en contraste a la clasificación de fonemas en los experimentos llevados a cabo en investigaciones previas, debido a que nuestro grupo está determinado a poner bajo prueba las capacidades secuenciales dinámicas de nuestro modelo para adquirir las reglas fonotácticas detrás de los vocabularios de entrenamiento. Finalmente, reportamos resultados de tareas de clasificación en 5 categorías vs. el desempeño en clasificación para 39 categorías en \cite{Lee:2009:UFL:2984093.2984217}. Por una parte, esta última diferencia podría haber actuado en favor de nuestro enfoque considerando el hecho de que es más fácil clasificar una categoría entre 5 que una entre 39. Por otro lado, es importante resaltar que los trabajos previos han tenido un entrenamiento mucho más extendido con más vocabularios, más voces, etc. En nuestro caso, presentamos condiciones de entrenamiento más dificultosas ya que nuestro modelo fue entrenado con 500 palabras de un vocabulario de tan sólo 5 palabras fonadas por 10 voces diferentes. Más allá de esta muestra pequeña, el desempeño obtenido por nuestro modelo neurocomputacional exhibe un nivel de generalización fonética significativo con la capacidad de adquirir reglas fonotácticas y de generalizar en contextos ambientales novedosos. 

%Although this is a compelling scenario, we have to be cautious since we cannot ignore important experimental differences from previous research results. First, our training material was very different from that found in previous works. We used corpora generated by synthesized voices instead of standardized \gls{timit} corpora. Given the high quality of the voices synthesized by \gls{festival} \cite{festival2014} and its flexibility in order to compose different kind of corpora--even with words that do not exist in any language--we considered that this was an appropriate initial experimental procedure to test our approach. Second, we pursued multisyllabic words classification tasks in contrast to the phone classification experiments carried out in previous research, since we mainly aimed to test the dynamic sequential capability of our model to acquire the phonotactic rules behind the training vocabularies. Finally, we reported results on 5-way classification tasks vs. performance on 39-way classification tasks in \cite{Lee:2009:UFL:2984093.2984217}. On the one hand, this last difference may have acted in favour of our approach considering that it is easier to classify one category among 5 than one among 39. On the other hand, it is important to highlight that previous works have had more extended training material with more vocabularies, more speakers, etc. In our case, we presented more difficult training conditions, since our model was trained with 500 words from a vocabulary of just 5 words uttered by 10 voices. Despite the small sample size, the performance obtained by our neurocomputational model exhibits a significant level of phonetic generalization with the capacity to acquire phonotactic rules and to generalize to novel environmental contexts.

Somos conscientes de la necesidad de más pruebas--en diferentes escenarios--con corpus estandardizados diferentes (como \gls{timit}) a los fines de poder analizar cabalmente las capacidades de nuestro enfoque. Sin embargo, nuestro objetivo principal en este trabajo fue el de probar la invarianza fonética secuencial exhibida por el \gls{el} bajo condiciones experimentales estrictamente controladas en las cuales conocíamos precisamente los niveles de ruido, reverberación y variaciones de tono con los cuales los estímulos fueron afectados. El material de entrenamiento para el \gls{el} incluyó sólo el corpus original de 500 palabras, pero aún más importante es el hecho de que ni el \gls{el} ni los clasificadores \gls{svm} fueron expuestos--durante sus entrenamientos--a las perturbaciones usadas para probar su desempeño en clasificación. El perfil de experimentación aplicado a este trabajo (Fig. \ref{fig:Experiment}) deja claro que el \gls{el} es completamente no supervisado y que toda la supervisión está limitada al algoritmo de \gls{svm}. Este es un hecho fundamental para demostrar la plausibilidad biológica de nuestra implementación ya que las restricciones fonotácticas en el lenguaje humano son adquiridas incidentalmente \cite{BRENT199693,saffran_1997} y por lo tanto, no hay lugar a supervisión alguna bajo tales condiciones.

%We are aware that more tests--in different scenarios--with different and standardized corpora (such as \gls{timit}) will be needed to analyze the capacities of our approach more deeply. Nevertheless, our main objective in the present work was to assess the sequential phonetic invariance exhibited by the \gls{el} under strictly controlled experimental conditions in which we precisely knew the levels of noise, reverberation and pitch variations with which the stimulus was affected. The \gls{el} training material included only the original corpora with 500 words, but more importantly, the \gls{el} was never exposed--during learning--to the disturbances used to test its classification performance. The experimental profile applied in this work (Fig. \ref{fig:Experiment}) makes it clear that the \gls{el} is completely unsupervised and that all supervision is limited to the \gls{svm} algorithm. This is a fundamental point to demonstrate the biological plausibility of our implementation since phonotactic constraints in a human language are learned incidentally \cite{BRENT199693,saffran_1997} and therefore, no supervision could be supported under such behavioral circumstances.


\section{Trabajo Futuro}

En futuras investigaciones, planeamos enriquecer las representaciones \gls{mrstsa} de nuestro modelo  desvinculando la sensibilidad de simetría y ancho de banda, incorporando un ventaneo temporal de múltiple resolución más sofisticado y un banco de filtro coclear más biológico como así también agregando codificación del nivel de sonido y características fisiológicas sub-corticales presentes en el núcleo coclear para agregar más selectividad de frecuencia. 

%In future research, we plan to enrich our model's \gls{mrstsa} representation by unlinking symmetry and bandwidth sensitivity, incorporating a more sophisticated multiresolution temporal windowing and a more biological cochlear filter bank, as well as adding sound level codification and also sub-cortical physiological characteristics present in the cochlear nucleus to add more frequency selectivity.

Además, propiedades emergentes podrían surgir de la adición de capas corticales subsecuentes--más allá del \glsfirst{el}--en la jerarquía de procesamiento del modelo. De esta manera podremos implementar conexiones distantes hacia atrás provenientes de ramificaciones dendríticas apicales las que traerán contexto a la implementación jerárquica no supervisada. Tambiém planeamos incorporar más plausibilidad biológica incrementando el número de células por \gls{cc} por medio del escalado masivo en simulaciones en \gls{hpc} y utilizando un \gls{gsom} por \gls{cc} para incorporar reclutamiento de recursos neuronales especializados en cada \gls{cc} dependientes de la dispersión estadística de sus estímulos \cite{Meyer19113}. Por ejemplo, un arreglo tetradimensional de unidades neuronales se podría usar para simular columnas corticales de aproximadamente 34000 células. De esta manera, miles de columnas corticales se podrían organizar en arreglos multidimensionales. Utilizando recursos computacionales de alto desempeño (como las computadoras ubicadas en el Top 500, \url{top500.org}), y asumiendo una columna cortical por nodo con 64 cores, podríamos estar corriendo 527 unidades neuronales por hilo de ejecución en una CPU. Además, configurando un arreglo tridimensional de 1000 columnas corticales por capa cortical, un modelo de 4 capas podría estar corriendo aproximadamente 256000 hilos. Tales simulaciones podrían devenir en una mejora de la adquisición fonotáctica así como en una mejora en las capacidades de generalización más allá de los niveles reportados en este trabajo.

%In addition, emergent dynamic properties could arise from the addition of subsequent cortical layers--beyond the \glsfirst{el}--in the processing pipeline of this model.  In this way we will be able to implement backward distal apical dendrites, which will bring context through an unsupervised hierarchical implementation. We are also planning to add more biological plausibility by means of increasing the number of cells per \gls{cc} with massively scaling \gls{hpc} simulations and using a \gls{gsom} per \gls{cc} in order to incorporate neural resource recruitment specialization in each \gls{cc} depending on the statistical dispersion of its stimuli \cite{Meyer19113}. For instance, a four-dimensional array of neural units can be employed to simulate cortical columns of approximately 34,000 cells. In this way, thousands of cortical columns can be organized in multidimensional arrays. Using a leadership-class supercomputer (e.g. resources from the Top 500 computing list, \url{top500.org}), and assuming one cortical column per compute node with 64 cores, we could be running 527 neural units per thread in a CPU. Furthermore, configuring a three-dimensional array of 1000 cortical columns per cortical layer, a model of 4 layers could be running on approximately 256,000 threads. Such simulations could allow us to leverage phonotactic acquisition as well as phonetic generalization capacities beyond the levels reported in this paper.

\section{Conclusiones}

%CO\textsubscript{2} Maecenas convallis mauris sit amet sem ultrices gravida. Etiam eget sapien nibh. Sed ac ipsum eget enim egestas ullamcorper nec euismod ligula. Curabitur fringilla pulvinar lectus consectetur pellentesque. Quisque augue sem, tincidunt sit amet feugiat eget, ullamcorper sed velit. 

%Sed non aliquet felis. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Mauris commodo justo ac dui pretium imperdiet. Sed suscipit iaculis mi at feugiat. Ut neque ipsum, luctus id lacus ut, laoreet scelerisque urna. Phasellus venenatis, tortor nec vestibulum mattis, massa tortor interdum felis, nec pellentesque metus tortor nec nisl. Ut ornare mauris tellus, vel dapibus arcu suscipit sed. Nam condimentum sem eget mollis euismod. Nullam dui urna, gravida venenatis dui et, tincidunt sodales ex. Nunc est dui, sodales sed mauris nec, auctor sagittis leo. Aliquam tincidunt, ex in facilisis elementum, libero lectus luctus est, non vulputate nisl augue at dolor. For more information, see \nameref{S1_Appendix}.

A través de simulaciones computacionales hemos demostrado que nuestra implementación de un modelo cortical mejora el desempeño en tareas de clasificación de palabras bajo condiciones ambientales específicas (como ruido blanco y reverberación) y para ciertas variaciones aplicadas a los estímulos auditivos (como corridas de tono). También demostramos la efectividad en la clasificación de palabras multisilábicas, lo cual sugiere que nuestra implementación de dinámica predictiva neurofisiológica más patrones de activación dispersos y estocásticos superan al algoritmo \gls{mrstsa} en términos de invariaza secuencial fonotáctica para las perturbaciones aplicadas a la señal de audio. Dado estos resultados, postulamos que las propiedades neuroanatómicas y neurofisiológicas incorporadas en nuestro modelo son potencialmente relevantes para el diseño de sistemas de inteligencia artificial y que podrían llegar a alcanzar niveles de invarianza y generalización fonética superiores a aquellos alcanzados por las arquitecturas actuales de aprendizaje profundo. 

%We demonstrate via a computational simulation that our implementation of the cortical model leverages the performance in word classification tasks under specific environmental conditions (e.g., white noise and reverberation) and for certain variances applied to the auditory stimuli (e.g., pitch variations). We also demonstrate effectiveness in classifying multisyllabic words, which suggests that our implementation of neurophysiological predictive dynamics plus stochastic sparse patterns of activation outperforms the MRSTSA algorithm in terms of phonotactic sequential invariance for disturbances applied to the audio signal. Given these promising results, we posit that neurophysiological and anatomical properties in our model are potentially relevant to the design of artificial intelligence systems and may achieve higher levels of phonetic invariance and generalization than the ones achieved by current deep learning architectures.


%In this paper, we analyze the sequential phonotactic invariant representations of high levels auditory pathway responses to complex phonetic sound stimuli.  We research such representations in relation to potentially relevant features in the auditory cortex. We incorporate such features in a computational model--inside the \gls{el} stage of a model called \gls{cstm}--and use \gls{svm} classification to test its performance for several word classification tasks. We compare our model performance with the performance achieved by the \gls{mrstsa} algorithm. The \gls{el} shows prominent sequential phonotactic acquisition capabilities, outperforming the \gls{mrstsa} algorithm for all the tests performed. Since the experimental profile is designed to asses the level of phonetic generalization on both algorithms, exposing the training material to environmental and pitch disturbances not present during learning, our model shows significant phonetic generalization capacity, leveraging the performance of the \gls{mrstsa}--even when it is seriously impaired. 

%In future research, we plan to enrich our model's \gls{mrstsa} representation by unlinking symmetry and bandwidth sensitivity, incorporating a more sophisticated multiresolution temporal windowing and a more biological cochlear filter bank, as well as adding sound level codification and also sub-cortical physiological characteristics present in the cochlear nucleus to add more frequency selectivity.

%Although future research with more experimental material will be needed, the research findings presented herein will be influential in terms of drawing new and alternative paths to current deep perception technologies in general and, more specifically, towards specific neurophysiological features plausibly relevant for phonotactic infant language acquisition.






