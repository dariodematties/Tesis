\addcontentsline{toc}{chapter}{Abstracto}

\begin{abstract}

Desde la segmentación de palabras en el flujo del habla hasta la adquisición de las reglas combinatorias que rijen el orden de dichas palabras en unidades oracionales cargadas de contenido semántico, el cerebro humano--en concordancia con su entorno--encuentra las regularidades relevantes que conducen al individuo a una interacción más gratificante con su medio social. 
Si bién en la actualidad la inteligencia artificial está realizando grandes avances, específicamente en el procesamiento del lenguaje natural desde la perspectiva del aprendizaje profundo--utilizando estratégias como redes neuronales convolucionales, redes neuronales recurrentes y hasta los avances recientes en la utilización de mecanismos de atención empleados en nuevos modelos denominados \emph{transformers}--lo cierto es que todas estas estratégias utilizan en el fondo el mismo conjunto de métodos de optimización para aprender.
Tales mecanismos, si bien de eficiencia extrema a la hora de evidenciar aprendizaje en la solución a problemas específicos del lenguaje, son de inconclusa justificación en el tejido cortical del cerebro.
En la presente tesina nos proponemos subsanar--al menos en parte--este problema tratando de construir modelos computacionales con más inspiración en la dinámica cortical de la que tienen actualmente los algoritmos preponderantes en el aprendizaje de máquinas.
Encaramos este desafío a distintos niveles del procesamiento del lenguaje, primero desde la perspectiva fonética y más tarde desde la gramática emergente en la dinámica cortical. También analizamos implementaciones paralelas eficientes en supercomputadoras de alta gama.
Nuestros modelos muestran resultados preliminares que podrían inspirar nuevos desarrollos para el aprendizaje de máquinas más basados en la corteza de los mamíferos para la resolución de problemas relacionados al procesamiento del lenguaje natural.
Consideramos este nuevo enfoque como relevante a la hora de fomentar futuras líneas de investigación con una mayor atención a la biología del cerebro humano.





%Existen muchas teorías computacionales desarrolladas para mejorar el desempeño en clasificación fonética obtenido desde flujos lingüísticos auditivos. Sin embargo, no se le ha prestado mucha atención a las características neuro-fisiológicas halladas en el tejido cortical. Nos enfocamos en el hecho de que los humanos, así como otros animales tienen la capacidad de clasificar de manera robusta unidades lingüísticas básicas--como fonemas--extraídas desde flujos acústicos complejos en los datos producidos por el habla. En este trabajo, introducimos un enfoque computacional biológicamente inspirado y completamente no supervisado que incorpora propiedades corticales neuro-fisiológicas y anatómicas claves. La capacidad de abstracción de características de este enfoque ha mostrado atributos de generalización e invarianza fonética prometedores. Este modelo mejora el desempeño en clasificación fonética de la técnica supervisada \gls{svm} para tareas de clasificación de palabras monosilábicas, bisilábicas y trisilábicas en presencia de ruido blanco, reverberación y variaciones de tono. De esta manera, el modelo computacional presentado en este trabajo supera claramente sofisticadas representaciones espectro-temporales de múltiple resolución de los datos lingüísticos fonéticos de entrada.

\end{abstract}
